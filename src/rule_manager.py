import os
import requests
import tarfile
import io
import re
import yaml
import yara
import time
from groq import Groq
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from typing import Dict, Optional, Tuple, List
from logger import logger
from config import config
from rate_limiter import rate_limit_manager

class RuleManagerError(Exception):
    """ë£° ê´€ë¦¬ ê´€ë ¨ ì—ëŸ¬"""
    pass

class GitHubSearchRateLimitError(Exception):
    """GitHub Search API 429 ì „ìš© ì—ëŸ¬ (ì¬ì‹œë„ ì œì–´ìš©)"""
    pass

class RuleManager:
    """
    íƒì§€ ë£° ìƒì„± ë° ê²€ì¦ ì „ë¬¸ê°€ (v2.2)
    
    v2.2 ë³€ê²½ì‚¬í•­:
    - rate_limit_manager í†µí•© (github_search ì „ìš© limit ì‚¬ìš©)
    - 429 ì‘ë‹µ ì‹œ Retry-After íŒŒì‹± í›„ ëŒ€ê¸°
    - retry ì „ëµì„ wait_fixed â†’ wait_exponentialë¡œ ë³€ê²½
    - ë£°ì…‹ ë‹¤ìš´ë¡œë“œì—ë„ rate limit ì ìš©
    - ë¶ˆí•„ìš”í•œ time.sleep(1) ì œê±° (rate_limit_managerê°€ ê´€ë¦¬)
    """
    
    def __init__(self):
        self.gh_token = os.environ.get("GH_TOKEN")
        self.groq_client = Groq(api_key=os.environ.get("GROQ_API_KEY"))
        self.model = config.MODEL_PHASE_1
        self.rules_cache: Dict[str, str] = {}
        
        logger.info("âœ… RuleManager ì´ˆê¸°í™” ì™„ë£Œ (ì •ê·œì‹ ê²€ì¦ ëª¨ë“œ)")
    
    # ====================================================================
    # [1] ê³µê°œ ë£° ê²€ìƒ‰
    # ====================================================================
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=2, min=4, max=30),
        retry=retry_if_exception_type(GitHubSearchRateLimitError)
    )
    def _search_github(self, repo: str, query: str) -> Optional[str]:
        """
        GitHub Code Searchë¡œ ê³µê°œ ë£° ì°¾ê¸°
        
        v2.2 ë³€ê²½ì‚¬í•­:
        - rate_limit_manager.check_and_wait("github_search") ì‚¬ìš©
        - 429 ì‘ë‹µ ì‹œ handle_429() í˜¸ì¶œ í›„ GitHubSearchRateLimitError ë°œìƒ
        - ì¼ë°˜ HTTP ì—ëŸ¬ëŠ” ì¬ì‹œë„í•˜ì§€ ì•Šê³  None ë°˜í™˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
        
        Args:
            repo: GitHub ë¦¬í¬ì§€í† ë¦¬
            query: ê²€ìƒ‰ì–´
        
        Returns:
            ë£° ì½”ë“œ ë˜ëŠ” None
        """
        logger.debug(f"GitHub ê²€ìƒ‰: {repo} / {query}")
        
        url = f"https://api.github.com/search/code?q=repo:{repo} {query}"
        headers = {
            "Authorization": f"token {self.gh_token}",
            "Accept": "application/vnd.github.v3+json"
        }
        
        try:
            # âœ… rate_limit_managerë¡œ í†µí•© ê´€ë¦¬
            rate_limit_manager.check_and_wait("github_search")
            
            response = requests.get(url, headers=headers, timeout=10)
            
            # âœ… 429 ì „ìš© ì²˜ë¦¬
            if response.status_code == 429:
                retry_after = response.headers.get("Retry-After")
                wait_seconds = float(retry_after) if retry_after else None
                
                logger.warning(
                    f"GitHub Search 429 ìˆ˜ì‹  (Retry-After: {wait_seconds or 'N/A'}ì´ˆ)"
                )
                
                rate_limit_manager.handle_429("github_search", wait_seconds)
                raise GitHubSearchRateLimitError("429 Too Many Requests")
            
            # 429 ì™¸ ì—ëŸ¬
            response.raise_for_status()
            
            # âœ… í˜¸ì¶œ ê¸°ë¡
            rate_limit_manager.record_call("github_search")
            
            data = response.json()
            
            if data.get('total_count', 0) > 0:
                item = data['items'][0]
                logger.info(f"âœ… ê³µê°œ ë£° ë°œê²¬: {item['html_url']}")
                
                raw_url = item['html_url'].replace(
                    'github.com', 'raw.githubusercontent.com'
                ).replace('/blob/', '/')
                
                # Raw íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì¼ë°˜ GitHub API ì‚¬ìš©)
                rate_limit_manager.check_and_wait("github")
                raw_response = requests.get(raw_url, timeout=10)
                raw_response.raise_for_status()
                rate_limit_manager.record_call("github")
                
                return raw_response.text
            
            logger.debug(f"ê³µê°œ ë£° ì—†ìŒ: {repo}")
            return None
            
        except GitHubSearchRateLimitError:
            raise  # ì¬ì‹œë„ë¥¼ ìœ„í•´ ì „íŒŒ
        except requests.exceptions.HTTPError as e:
            # 429 ì™¸ì˜ HTTP ì—ëŸ¬ (403, 422 ë“±) â†’ ì¬ì‹œë„í•˜ì§€ ì•Šê³  None
            logger.warning(f"GitHub ê²€ìƒ‰ HTTP ì—ëŸ¬ ({repo}): {e}")
            return None
        except requests.exceptions.RequestException as e:
            # ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ â†’ ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  None
            logger.warning(f"GitHub ê²€ìƒ‰ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ({repo}): {e}")
            return None
        except Exception as e:
            logger.error(f"GitHub ê²€ìƒ‰ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
            return None
    
    def _fetch_network_rules(self, cve_id: str) -> List[Dict[str, str]]:
        """
        ë„¤íŠ¸ì›Œí¬ íƒì§€ ë£° ìˆ˜ì§‘ (Snort + Suricata)
        
        ê²€ìƒ‰ ëŒ€ìƒ:
        1. Snort 2.9 Community Rules
        2. Snort 3 Community Rules
        3. Snort 2.9 ET Open
        4. Suricata 5 ET Open
        5. Suricata 7 ET Open
        """
        logger.debug(f"ë„¤íŠ¸ì›Œí¬ ë£°ì…‹ ê²€ìƒ‰ ì‹œì‘: {cve_id}")
        
        found_rules = []
        
        if not self.rules_cache:
            self._download_all_rulesets()
        
        for ruleset_name, ruleset_content in self.rules_cache.items():
            for line in ruleset_content.splitlines():
                if cve_id in line and "alert" in line and not line.strip().startswith("#"):
                    engine_type = self._detect_engine_type(ruleset_name)
                    
                    found_rules.append({
                        "code": line.strip(),
                        "source": ruleset_name,
                        "engine": engine_type
                    })
                    
                    logger.info(f"âœ… {ruleset_name}ì—ì„œ ë£° ë°œê²¬")
                    break
        
        if not found_rules:
            logger.debug("ëª¨ë“  ë„¤íŠ¸ì›Œí¬ ë£°ì…‹ì—ì„œ ì°¾ì§€ ëª»í•¨")
        else:
            logger.info(f"âœ… ì´ {len(found_rules)}ê°œ ì—”ì§„ì˜ ë£° ë°œê²¬")
        
        return found_rules
    
    def _download_all_rulesets(self):
        """
        ëª¨ë“  ë„¤íŠ¸ì›Œí¬ ë£°ì…‹ ë‹¤ìš´ë¡œë“œ (rate_limit_manager ì ìš©)
        
        v2.2: ruleset_download rate limit ì‚¬ìš©
        """
        logger.info("ğŸ“¥ ë„¤íŠ¸ì›Œí¬ ë£°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        # ===== 1. Snort Community Rules =====
        
        # 1-1. Snort 2.9 Community
        try:
            rate_limit_manager.check_and_wait("ruleset_download")
            logger.debug("  - Snort 2.9 Community ë‹¤ìš´ë¡œë“œ ì¤‘...")
            response = requests.get(
                "https://www.snort.org/downloads/community/community-rules.tar.gz",
                timeout=15
            )
            rate_limit_manager.record_call("ruleset_download")
            
            if response.status_code == 200:
                with tarfile.open(fileobj=io.BytesIO(response.content), mode="r:gz") as tar:
                    for member in tar.getmembers():
                        if "community.rules" in member.name:
                            f = tar.extractfile(member)
                            content = f.read().decode('utf-8', errors='ignore')
                            self.rules_cache["Snort 2.9 Community"] = content
                            logger.info("  âœ… Snort 2.9 Community ë¡œë“œ ì™„ë£Œ")
                            break
        except Exception as e:
            logger.warning(f"  âš ï¸ Snort 2.9 Community ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 1-2. Snort 3 Community
        try:
            rate_limit_manager.check_and_wait("ruleset_download")
            logger.debug("  - Snort 3 Community ë‹¤ìš´ë¡œë“œ ì¤‘...")
            response = requests.get(
                "https://www.snort.org/downloads/community/snort3-community-rules.tar.gz",
                timeout=15
            )
            rate_limit_manager.record_call("ruleset_download")
            
            if response.status_code == 200:
                with tarfile.open(fileobj=io.BytesIO(response.content), mode="r:gz") as tar:
                    for member in tar.getmembers():
                        if "snort3-community.rules" in member.name:
                            f = tar.extractfile(member)
                            content = f.read().decode('utf-8', errors='ignore')
                            self.rules_cache["Snort 3 Community"] = content
                            logger.info("  âœ… Snort 3 Community ë¡œë“œ ì™„ë£Œ")
                            break
        except Exception as e:
            logger.warning(f"  âš ï¸ Snort 3 Community ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ===== 2. Emerging Threats Open =====
        et_rulesets = [
            ("Snort 2.9 ET Open", "https://rules.emergingthreats.net/open/snort-2.9.0/emerging-all.rules"),
            ("Suricata 5 ET Open", "https://rules.emergingthreats.net/open/suricata-5.0/emerging-all.rules"),
            ("Suricata 7 ET Open", "https://rules.emergingthreats.net/open/suricata-7.0/emerging-all.rules"),
        ]
        
        for name, url in et_rulesets:
            try:
                rate_limit_manager.check_and_wait("ruleset_download")
                logger.debug(f"  - {name} ë‹¤ìš´ë¡œë“œ ì¤‘...")
                response = requests.get(url, timeout=15)
                rate_limit_manager.record_call("ruleset_download")
                
                if response.status_code == 200:
                    self.rules_cache[name] = response.text
                    logger.info(f"  âœ… {name} ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.debug(f"  âš ï¸ {name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            except Exception as e:
                logger.debug(f"  âš ï¸ {name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        logger.info(f"âœ… ë£°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(self.rules_cache)}ê°œ ì†ŒìŠ¤)")
    
    def _detect_engine_type(self, ruleset_name: str) -> str:
        """ë£°ì…‹ ì´ë¦„ì—ì„œ ì—”ì§„ íƒ€ì… ì¶”ì¶œ"""
        name_lower = ruleset_name.lower()
        
        if "snort 2.9" in name_lower or "snort 2" in name_lower:
            return "snort2"
        elif "snort 3" in name_lower or "snort3" in name_lower:
            return "snort3"
        elif "suricata 5" in name_lower:
            return "suricata5"
        elif "suricata 7" in name_lower:
            return "suricata7"
        elif "suricata edge" in name_lower:
            return "suricata-edge"
        else:
            return "unknown"
    
    # ====================================================================
    # [2] ë£° ê²€ì¦ (ì •ê·œì‹ ê¸°ë°˜)
    # ====================================================================
    
    def _validate_sigma(self, code: str) -> bool:
        """Sigma ë£° ê²€ì¦ (YAML íŒŒì‹± + í•„ìˆ˜ í•„ë“œ í™•ì¸)"""
        try:
            data = yaml.safe_load(code)
            
            if not isinstance(data, dict):
                logger.warning("Sigma: YAMLì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
                return False
            
            required = ['title', 'logsource', 'detection']
            for field in required:
                if field not in data:
                    logger.warning(f"Sigma: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ - {field}")
                    return False
            
            logsource = data['logsource']
            if 'product' not in logsource and 'category' not in logsource:
                logger.warning("Sigma: logsourceì— product ë˜ëŠ” category í•„ìš”")
                return False
            
            logger.debug("âœ… Sigma ê²€ì¦ í†µê³¼")
            return True
            
        except yaml.YAMLError as e:
            logger.warning(f"Sigma: YAML íŒŒì‹± ì‹¤íŒ¨ - {e}")
            return False
        except Exception as e:
            logger.warning(f"Sigma: ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ - {e}")
            return False
    
    def _validate_yara(self, code: str) -> bool:
        """Yara ë£° ê²€ì¦ (ì»´íŒŒì¼ í…ŒìŠ¤íŠ¸)"""
        try:
            yara.compile(source=code)
            logger.debug("âœ… Yara ê²€ì¦ í†µê³¼")
            return True
        except yara.SyntaxError as e:
            logger.warning(f"Yara: ë¬¸ë²• ì—ëŸ¬ - {e}")
            return False
        except Exception as e:
            logger.warning(f"Yara: ì»´íŒŒì¼ ì‹¤íŒ¨ - {e}")
            return False
    
    def _validate_network_rule(self, code: str) -> bool:
        """ë„¤íŠ¸ì›Œí¬ ë£° ê²€ì¦ (6ë‹¨ê³„ ì •ê·œì‹)"""
        code = code.strip()
        
        # 1ë‹¨ê³„: ê¸°ë³¸ êµ¬ì¡°
        if not re.match(r'^(alert|log|pass|drop|reject|sdrop)\s+(tcp|udp|icmp|ip)\s', code, re.IGNORECASE):
            logger.warning("ë„¤íŠ¸ì›Œí¬ ë£°: ê¸°ë³¸ êµ¬ì¡° ë¶ˆì¼ì¹˜")
            return False
        
        # 2ë‹¨ê³„: í•„ìˆ˜ ìš”ì†Œ
        required_patterns = [
            (r'\$\w+', "ë³€ìˆ˜"),
            (r'\d+', "í¬íŠ¸"),
            (r'->', "ë°©í–¥"),
            (r'\(', "ì˜µì…˜ ì‹œì‘"),
            (r'\)', "ì˜µì…˜ ë"),
        ]
        for pattern, name in required_patterns:
            if not re.search(pattern, code):
                logger.warning(f"ë„¤íŠ¸ì›Œí¬ ë£°: {name} ëˆ„ë½")
                return False
        
        # 3ë‹¨ê³„: msg í•„ë“œ
        if not re.search(r'msg:\s*["\'].*?["\']', code):
            logger.warning("ë„¤íŠ¸ì›Œí¬ ë£°: msg í•„ë“œ ëˆ„ë½")
            return False
        
        # 4ë‹¨ê³„: sid í•„ë“œ
        if not re.search(r'sid:\s*\d+', code):
            logger.warning("ë„¤íŠ¸ì›Œí¬ ë£°: sid í•„ë“œ ëˆ„ë½")
            return False
        
        # 5ë‹¨ê³„: ë¬¸ë²• ì˜¤ë¥˜
        invalid_patterns = [
            (r'\(\s*\)', "ë¹ˆ ì˜µì…˜ ê´„í˜¸"),
            (r';\s*;', "ì—°ì† ì„¸ë¯¸ì½œë¡ "),
            (r'\$[^\w]', "ì˜ëª»ëœ ë³€ìˆ˜"),
        ]
        for pattern, name in invalid_patterns:
            if re.search(pattern, code):
                logger.warning(f"ë„¤íŠ¸ì›Œí¬ ë£°: {name} ê°ì§€")
                return False
        
        # 6ë‹¨ê³„: ê´„í˜¸ ê· í˜•
        if code.count('(') != code.count(')'):
            logger.warning("ë„¤íŠ¸ì›Œí¬ ë£°: ê´„í˜¸ ë¶ˆê· í˜•")
            return False
        
        logger.debug("âœ… ë„¤íŠ¸ì›Œí¬ ë£° ì •ê·œì‹ ê²€ì¦ í†µê³¼")
        return True
    
    # ====================================================================
    # [3] AI ë£° ìƒì„±
    # ====================================================================
    
    def _check_observables(self, cve_data: Dict) -> Tuple[bool, str, List[str]]:
        """Observable Gate: êµ¬ì²´ì  ì§€í‘œ í™•ì¸"""
        desc = cve_data['description'].lower()
        
        indicators = []
        indicator_details = []
        
        # íŒŒì¼ ê²½ë¡œ
        if '/' in cve_data['description']:
            indicators.append("íŒŒì¼ ê²½ë¡œ")
            paths = re.findall(r'/[a-zA-Z0-9_\-/\.]+', cve_data['description'])
            if paths:
                indicator_details.append(f"íŒŒì¼ ê²½ë¡œ ({paths[0]})")
            else:
                indicator_details.append("íŒŒì¼ ê²½ë¡œ")
        
        # ì›¹ íŒŒì¼
        web_files = ['.php', '.jsp', '.asp', '.cgi']
        for ext in web_files:
            if ext in desc:
                indicators.append("ì›¹ íŒŒì¼")
                indicator_details.append(f"ì›¹ íŒŒì¼ ({ext})")
                break
        
        # URL íŒŒë¼ë¯¸í„°
        if 'parameter' in desc or 'param=' in desc or '?' in cve_data['description']:
            indicators.append("URL íŒŒë¼ë¯¸í„°")
            params = re.findall(r'\b\w+\s*=', cve_data['description'])
            if params:
                indicator_details.append(f"URL íŒŒë¼ë¯¸í„° ({params[0]})")
            else:
                indicator_details.append("URL íŒŒë¼ë¯¸í„°")
        
        # HTTP í—¤ë”
        if ('header' in desc and ('http' in desc or 'user-agent' in desc)):
            indicators.append("HTTP í—¤ë”")
            indicator_details.append("HTTP í—¤ë”")
        
        # Hex ê°’
        hex_match = re.search(r'0x[0-9a-f]{2,}', desc)
        if hex_match:
            indicators.append("Hex ê°’")
            indicator_details.append(f"Hex ê°’ ({hex_match.group()})")
        
        # ë ˆì§€ìŠ¤íŠ¸ë¦¬
        if 'registry' in desc and 'hk' in desc:
            indicators.append("ë ˆì§€ìŠ¤íŠ¸ë¦¬")
            indicator_details.append("ë ˆì§€ìŠ¤íŠ¸ë¦¬ í‚¤")
        
        # í¬íŠ¸
        port_match = re.search(r'port\s+(\d+)', desc)
        if port_match:
            indicators.append("í¬íŠ¸ ë²ˆí˜¸")
            indicator_details.append(f"í¬íŠ¸ ({port_match.group(1)})")
        
        has_enough = len(indicators) >= 1
        
        if has_enough:
            reason = f"ë°œê²¬ëœ ì§€í‘œ: {', '.join(indicator_details)}"
        else:
            reason = "êµ¬ì²´ì  ì§€í‘œ ë¶€ì¡±"
        
        return has_enough, reason, indicator_details
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=2, min=4, max=30)
    )
    def _generate_ai_rule(self, rule_type: str, cve_data: Dict, analysis: Optional[Dict] = None) -> Optional[Tuple[str, List[str]]]:
        """
        AI ê¸°ë°˜ íƒì§€ ë£° ìƒì„±
        
        v2.2: groq rate limit ì—°ë™
        """
        logger.debug(f"AI {rule_type} ìƒì„± ì‹œë„")
        
        # Observable Gate
        indicator_details = []
        if rule_type not in ["Sigma", "sigma"]:
            has_indicators, reason, indicator_details = self._check_observables(cve_data)
            if not has_indicators:
                logger.info(f"â›” {rule_type} ìƒì„± SKIP: {reason}")
                return None
            else:
                logger.debug(f"âœ… Observable Gate í†µê³¼: {reason}")
        
        prompt = self._build_rule_prompt(rule_type, cve_data, analysis)
        
        try:
            # âœ… Groq rate limit ì²´í¬
            rate_limit_manager.check_and_wait("groq")
            
            response = self.groq_client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=config.GROQ_RULE_PARAMS["temperature"],
                top_p=config.GROQ_RULE_PARAMS["top_p"],
                max_completion_tokens=config.GROQ_RULE_PARAMS["max_completion_tokens"],
                reasoning_effort=config.GROQ_RULE_PARAMS["reasoning_effort"]
            )
            
            # âœ… Groq í˜¸ì¶œ ê¸°ë¡
            rate_limit_manager.record_call("groq")
            
            content = response.choices[0].message.content.strip()
            content = re.sub(r"```[a-z]*\n|```", "", content).strip()
            
            if content == "SKIP" or not content:
                logger.info(f"â›” AIê°€ {rule_type} ìƒì„± ê±°ë¶€ (ê·¼ê±° ë¶€ì¡±)")
                return None
            
            # ê²€ì¦
            is_valid = False
            if rule_type in ["Snort", "Suricata", "snort", "suricata"]:
                is_valid = self._validate_network_rule(content)
            elif rule_type in ["Yara", "yara"]:
                is_valid = self._validate_yara(content)
            elif rule_type in ["Sigma", "sigma"]:
                is_valid = self._validate_sigma(content)
            
            if is_valid:
                logger.info(f"âœ… AI {rule_type} ìƒì„± ë° ê²€ì¦ ì„±ê³µ")
                return (content, indicator_details)
            else:
                logger.warning(f"âŒ AI {rule_type} ê²€ì¦ ì‹¤íŒ¨")
                logger.debug(f"ì‹¤íŒ¨í•œ ë£°:\n{content}")
                return None
                
        except Exception as e:
            logger.error(f"AI ë£° ìƒì„± ì—ëŸ¬: {e}")
            raise
    
    def _build_rule_prompt(self, rule_type: str, cve_data: Dict, analysis: Optional[Dict] = None) -> str:
        """
        AIë¥¼ ìœ„í•œ ë£° ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        v2.3: References, Affected Products, AI Analysis ì¶”ê°€
        """
        references_str = "None"
        if cve_data.get('references'):
            refs = cve_data['references'][:3]
            references_str = "\n".join([f"- {ref}" for ref in refs])
        
        affected_str = "Unknown"
        if cve_data.get('affected'):
            affected_items = []
            for item in cve_data['affected'][:3]:
                vendor = item.get('vendor', 'Unknown')
                product = item.get('product', 'Unknown')
                versions = item.get('versions', 'Unknown')
                affected_items.append(f"- {vendor} {product} ({versions})")
            if affected_items:
                affected_str = "\n".join(affected_items)
        
        analysis_section = ""
        if analysis:
            root_cause = analysis.get('root_cause', 'N/A')
            attack_scenario = analysis.get('scenario', analysis.get('attack_scenario', 'N/A'))
            if root_cause != 'N/A' or attack_scenario != 'N/A':
                analysis_section = f"""
[AI Analysis - Additional Context]
Root Cause: {root_cause}
Attack Scenario: {attack_scenario}
"""
        
        base_prompt = f"""
You are a Senior Detection Engineer specializing in {rule_type} rules.
Write a valid {rule_type} detection rule for {cve_data['id']}.

[Context]
CVE-ID: {cve_data['id']}
Description: {cve_data['description']}
CVSS Vector: {cve_data.get('cvss_vector', 'N/A')}
CWE: {', '.join(cve_data.get('cwe', []))}

[Affected Products]
{affected_str}

[References]
{references_str}
{analysis_section}
[CRITICAL REQUIREMENTS]
1. **Observable Gate**: If no concrete indicator exists, return exactly: SKIP
2. **No Hallucination**: Use ONLY what's in the description, references, and analysis
3. **Syntax**: Follow standard {rule_type} syntax strictly
4. **Product-Specific**: If affected products are known, tailor the rule
5. **Conservative**: When uncertain, return SKIP

[Output Format]
- Return ONLY the raw rule code (no markdown, no explanation)
- If insufficient information, return exactly: SKIP
"""
        
        if rule_type in ["Snort", "Suricata", "snort", "suricata"]:
            base_prompt += """
[Snort/Suricata Template]
alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $HTTP_PORTS (
    msg:"CVE-XXXX Exploit Attempt";
    flow:to_server,established;
    content:"specific_string"; http_uri;
    pcre:"/pattern/i";
    classtype:web-application-attack;
    sid:1000001; rev:1;
)

Requirements:
- MUST include: msg, sid
- Use actual content/pcre from description
"""
        elif rule_type in ["Yara", "yara"]:
            base_prompt += """
[Yara Template]
rule CVE_XXXX_Indicator {
    meta:
        description = "Detects CVE-XXXX"
        author = "Argus-AI"
    strings:
        $s1 = "specific_string" ascii
    condition:
        any of ($s*)
}
"""
        elif rule_type in ["Sigma", "sigma"]:
            base_prompt += """
[Sigma Template]
title: CVE-XXXX Detection
status: experimental
description: Detects CVE-XXXX
logsource:
    product: windows
    category: process_creation
detection:
    selection:
        CommandLine|contains: 'pattern'
    condition: selection
level: high
"""
        
        return base_prompt
    
    # ====================================================================
    # [4] ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
    # ====================================================================
    
    def get_rules(self, cve_data: Dict, feasibility: bool, analysis: Optional[Dict] = None) -> Dict:
        """
        CVEì— ëŒ€í•œ íƒì§€ ë£° ìˆ˜ì§‘
        
        ìš°ì„ ìˆœìœ„:
        1. ê³µê°œ ë£° (ì‹ ë¢°ë„ 100%)
        2. AI ìƒì„± ë£° (Observable Gate í†µê³¼ ì‹œ, ê²€ì¦ í›„ ì œê³µ)
        """
        rules = {"sigma": None, "network": [], "yara": None}
        cve_id = cve_data['id']
        
        logger.info(f"ë£° ìˆ˜ì§‘ ì‹œì‘: {cve_id}")
        
        # ===== Sigma =====
        try:
            public_sigma = self._search_github("SigmaHQ/sigma", f"{cve_id} filename:.yml")
            if public_sigma:
                rules['sigma'] = {
                    "code": public_sigma,
                    "source": "Public (SigmaHQ)",
                    "verified": True,
                    "indicators": None
                }
            else:
                ai_result = self._generate_ai_rule("Sigma", cve_data, analysis)
                if ai_result:
                    ai_sigma, indicators = ai_result
                    rules['sigma'] = {
                        "code": f"# âš ï¸ AI-Generated - Review Required\n{ai_sigma}",
                        "source": "AI Generated (Validated)",
                        "verified": False,
                        "indicators": indicators
                    }
        except Exception as e:
            logger.warning(f"Sigma ë£° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ===== ë„¤íŠ¸ì›Œí¬ ë£° (Snort + Suricata) =====
        try:
            network_rules = self._fetch_network_rules(cve_id)
            
            if network_rules:
                for rule_info in network_rules:
                    rules['network'].append({
                        "code": rule_info["code"],
                        "source": f"Public ({rule_info['source']})",
                        "engine": rule_info["engine"],
                        "verified": True,
                        "indicators": None
                    })
            else:
                ai_result = self._generate_ai_rule("Snort", cve_data, analysis)
                if ai_result:
                    ai_network, indicators = ai_result
                    rules['network'].append({
                        "code": f"# âš ï¸ AI-Generated - Review Required\n{ai_network}",
                        "source": "AI Generated (Regex Validated)",
                        "engine": "generic",
                        "verified": False,
                        "indicators": indicators
                    })
        except Exception as e:
            logger.warning(f"ë„¤íŠ¸ì›Œí¬ ë£° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ===== Yara =====
        try:
            public_yara = self._search_github("Yara-Rules/rules", f"{cve_id} filename:.yar")
            if public_yara:
                rules['yara'] = {
                    "code": public_yara,
                    "source": "Public (Yara-Rules)",
                    "verified": True,
                    "indicators": None
                }
            else:
                ai_result = self._generate_ai_rule("Yara", cve_data, analysis)
                if ai_result:
                    ai_yara, indicators = ai_result
                    rules['yara'] = {
                        "code": f"// âš ï¸ AI-Generated - Review Required\n{ai_yara}",
                        "source": "AI Generated (Compiled)",
                        "verified": False,
                        "indicators": indicators
                    }
        except Exception as e:
            logger.warning(f"Yara ë£° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ê²°ê³¼ ìš”ì•½
        sigma_found = "âœ…" if rules['sigma'] else "âŒ"
        network_count = len(rules['network'])
        network_found = f"âœ… ({network_count}ê°œ)" if network_count > 0 else "âŒ"
        yara_found = "âœ…" if rules['yara'] else "âŒ"
        
        logger.info(f"ë£° ìˆ˜ì§‘ ì™„ë£Œ: Sigma {sigma_found}, Network {network_found}, Yara {yara_found}")
        
        return rules
