import requests
import datetime
import pytz
import os
import re
import json
import time
import hashlib
from typing import List, Dict, Set, Optional
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from logger import logger
from rate_limiter import rate_limit_manager

class CollectorError(Exception):
    """ë°ì´í„° ìˆ˜ì§‘ ê´€ë ¨ ì—ëŸ¬"""
    pass

class Collector:
    # ë²Œí¬ ë©”ì¸í…Œë„ŒìŠ¤ ì»¤ë°‹ ê°ì§€ íŒ¨í„´
    BULK_PATTERNS = re.compile(
        r'(format|standardize|normalize|batch|bulk|automated|metadata|date.?time|migration|mass.?update|reformat)',
        re.IGNORECASE
    )

    def __init__(self):
        self.kev_set: Set[str] = set()
        self.vulncheck_kev_set: Set[str] = set()
        self.epss_cache: Dict[str, float] = {}
        self.headers = {
            "Authorization": f"token {os.environ.get('GH_TOKEN')}",
            "Accept": "application/vnd.github.v3+json"
        }
        # config importëŠ” ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•´ ì§€ì—°
        try:
            from config import config
            self.bulk_threshold = config.PERFORMANCE.get("bulk_commit_threshold", 100)
        except Exception:
            self.bulk_threshold = 100
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type(requests.exceptions.RequestException)
    )
    def fetch_kev(self) -> bool:
        """CISA KEV ëª©ë¡ ë‹¤ìš´ë¡œë“œ"""
        url = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
        
        try:
            rate_limit_manager.check_and_wait("kev")
            logger.info("Fetching CISA KEV list...")
            
            response = requests.get(url, timeout=15)
            response.raise_for_status()
            rate_limit_manager.record_call("kev")
            
            data = response.json()
            self.kev_set = {vuln['cveID'] for vuln in data.get('vulnerabilities', [])}
            
            logger.info(f"Loaded {len(self.kev_set)} KEV entries")
            return True
            
        except requests.exceptions.Timeout:
            logger.error("KEV API timeout after 15s")
            return False
        except requests.exceptions.RequestException as e:
            logger.error(f"KEV fetch failed: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in fetch_kev: {e}")
            return False
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def fetch_epss(self, cve_ids: List[str]) -> Dict[str, float]:
        """EPSS ì ìˆ˜ ë°°ì¹˜ ìˆ˜ì§‘"""
        if not cve_ids:
            return {}
        
        chunk_size = 50
        total_chunks = (len(cve_ids) + chunk_size - 1) // chunk_size
        
        logger.info(f"Fetching EPSS scores for {len(cve_ids)} CVEs ({total_chunks} batches)")
        
        for i in range(0, len(cve_ids), chunk_size):
            chunk = cve_ids[i:i + chunk_size]
            chunk_num = (i // chunk_size) + 1
            
            try:
                rate_limit_manager.check_and_wait("epss")
                
                url = f"https://api.first.org/data/v1/epss?cve={','.join(chunk)}"
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                rate_limit_manager.record_call("epss")
                
                for item in response.json().get('data', []):
                    cve_id = item.get('cve')
                    epss = float(item.get('epss', 0.0))
                    self.epss_cache[cve_id] = epss
                
                logger.debug(f"EPSS batch {chunk_num}/{total_chunks} complete")
                
            except Exception as e:
                logger.warning(f"EPSS batch {chunk_num} failed: {e}")
                continue
        
        return self.epss_cache
    
    # ====================================================================
    # [3] ì½˜í…ì¸  í•´ì‹œ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í•„í„°ë§
    # ====================================================================

    def _compute_content_hash(self, json_data: dict) -> str:
        """CVE JSONì—ì„œ ì˜ë¯¸ìˆëŠ” í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ SHA-256 í•´ì‹œ ìƒì„±.

        ë‚ ì§œ/ì‹œê°„, assignerOrgId, serial ë“± ë©”íƒ€ë°ì´í„° í•„ë“œëŠ” ì œì™¸í•˜ì—¬
        ë²Œí¬ ë©”íƒ€ë°ì´í„° íŒ¨ì¹˜(ë‚ ì§œ í˜•ì‹ ë³€ê²½ ë“±)ì— ì˜í–¥ë°›ì§€ ì•ŠìŒ.
        """
        cna = json_data.get('containers', {}).get('cna', {})
        meaningful = {
            "descriptions": cna.get('descriptions', []),
            "affected": cna.get('affected', []),
            "metrics": cna.get('metrics', []),
            "problemTypes": cna.get('problemTypes', []),
            "references": cna.get('references', []),
            "title": cna.get('title', ''),
            "state": json_data.get('cveMetadata', {}).get('state', ''),
        }
        canonical = json.dumps(meaningful, sort_keys=True, separators=(',', ':'))
        return hashlib.sha256(canonical.encode()).hexdigest()

    def _is_bulk_commit(self, commit_detail: dict) -> bool:
        """ë²Œí¬ ë©”ì¸í…Œë„ŒìŠ¤ ì»¤ë°‹ì¸ì§€ ê°ì§€.

        ì¡°ê±´: íŒŒì¼ ìˆ˜ê°€ threshold ì´ìƒì´ë©´ ë²Œí¬ë¡œ ê°„ì£¼.
        ì»¤ë°‹ ë©”ì‹œì§€ì— ë²Œí¬ íŒ¨í„´ì´ ìˆìœ¼ë©´ ì¶”ê°€ í™•ì‹ .
        """
        files = commit_detail.get('files', [])
        file_count = len(files)
        message = commit_detail.get('commit', {}).get('message', '')

        # íŒŒì¼ ìˆ˜ë§Œìœ¼ë¡œ ë²Œí¬ íŒë‹¨ (threshold ì´ìƒì´ë©´ í•­ìƒ ë²Œí¬)
        if file_count >= self.bulk_threshold:
            if self.BULK_PATTERNS.search(message):
                logger.info(f"ë²Œí¬ ì»¤ë°‹ ê°ì§€: {file_count}ê°œ íŒŒì¼, ë©”ì‹œì§€ íŒ¨í„´ ë§¤ì¹­")
            else:
                logger.info(f"ë²Œí¬ ì»¤ë°‹ ê°ì§€: {file_count}ê°œ íŒŒì¼ (ëŒ€ëŸ‰ ìˆ˜ì •)")
            return True

        return False

    def _extract_cve_id(self, filename: str) -> Optional[str]:
        """íŒŒì¼ëª…ì—ì„œ CVE ID ì¶”ì¶œ"""
        if filename.endswith(".json") and "CVE-" in filename:
            match = re.search(r'(CVE-\d{4}-\d{4,7})', filename)
            if match:
                return match.group(1)
        return None

    def _fetch_raw_cve_json(self, cve_id: str) -> Optional[dict]:
        """raw.githubusercontent.comì—ì„œ CVE JSONë§Œ ë‹¤ìš´ë¡œë“œ (API í•œë„ ë¯¸ì†Œëª¨).

        enrich_cve()ì™€ ë‹¬ë¦¬ NVD/EPSS/PoC ë“± ì™¸ë¶€ API í˜¸ì¶œ ì—†ìŒ.
        í•´ì‹œ ë¹„êµìš© ê²½ëŸ‰ ì‚¬ì „ ê²€ì‚¬ì— ì‚¬ìš©.
        """
        try:
            parts = cve_id.split('-')
            year, id_num = parts[1], parts[2]
            group_dir = "0xxx" if len(id_num) < 4 else id_num[:-3] + "xxx"

            raw_url = f"https://raw.githubusercontent.com/CVEProject/cvelistV5/main/cves/{year}/{group_dir}/{cve_id}.json"
            response = requests.get(raw_url, timeout=10)
            response.raise_for_status()

            return response.json()
        except Exception as e:
            logger.debug(f"{cve_id} raw JSON ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    def fetch_recent_cves(self, hours: int = 2, db=None) -> List[dict]:
        """GitHub CVEProjectì—ì„œ ìµœê·¼ CVE ìˆ˜ì§‘ (ìŠ¤ë§ˆíŠ¸ í•„í„°ë§).

        3ë‹¨ê³„ í•„í„°ë§:
        1. ì»¤ë°‹ì—ì„œ CVE ID ì¶”ì¶œ + ë²Œí¬ ì»¤ë°‹ ê°ì§€
        2. ì¼ë°˜ ì»¤ë°‹ CVE â†’ ì „ë¶€ ì²˜ë¦¬ ëŒ€ìƒ
        3. ë²Œí¬ ì»¤ë°‹ CVE â†’ ì½˜í…ì¸  í•´ì‹œ ë¹„êµ â†’ ë©”íƒ€ë°ì´í„°ë§Œ ë³€ê²½ëœ ê²ƒ ìŠ¤í‚µ

        Returns:
            List[dict]: [{"cve_id": str, "is_new": bool}, ...]
        """
        now = datetime.datetime.now(pytz.UTC)
        since_str = (now - datetime.timedelta(hours=hours)).strftime("%Y-%m-%dT%H:%M:%SZ")

        url = f"https://api.github.com/repos/CVEProject/cvelistV5/commits?since={since_str}"

        try:
            rate_limit_manager.check_and_wait("github")
            logger.info(f"Fetching CVEs from last {hours} hours...")

            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            rate_limit_manager.record_call("github")

            commits = response.json()

            seen = set()
            normal_cve_ids = []
            bulk_cve_ids = []
            result = []
            skipped = 0

            # Phase 1: ëª¨ë“  ì»¤ë°‹ì—ì„œ CVE ID ìˆ˜ì§‘ + ë²Œí¬ ì—¬ë¶€ íƒœê¹…
            for commit in commits:
                rate_limit_manager.check_and_wait("github")

                commit_response = requests.get(commit['url'], headers=self.headers, timeout=10)
                commit_response.raise_for_status()
                rate_limit_manager.record_call("github")

                commit_detail = commit_response.json()
                is_bulk = self._is_bulk_commit(commit_detail)

                for file_info in commit_detail.get('files', []):
                    cve_id = self._extract_cve_id(file_info['filename'])
                    if not cve_id or cve_id in seen:
                        continue
                    seen.add(cve_id)

                    if is_bulk:
                        bulk_cve_ids.append(cve_id)
                    else:
                        normal_cve_ids.append(cve_id)

            # Phase 2: ì¼ë°˜ ì»¤ë°‹ CVE â†’ ì „ë¶€ ì²˜ë¦¬ ëŒ€ìƒ
            for cve_id in normal_cve_ids:
                result.append({"cve_id": cve_id, "is_new": True})

            # Phase 3: ë²Œí¬ ì»¤ë°‹ CVE â†’ ë°°ì¹˜ í•´ì‹œ ë¹„êµë¡œ í•„í„°ë§
            if bulk_cve_ids:
                if db:
                    existing_hashes = db.batch_get_content_hashes(bulk_cve_ids)
                    logger.info(f"ë²Œí¬ ì»¤ë°‹ CVE {len(bulk_cve_ids)}ê±´ ì¤‘ DB í•´ì‹œ {len(existing_hashes)}ê±´ ë°œê²¬")

                    for cve_id in bulk_cve_ids:
                        old_hash = existing_hashes.get(cve_id)
                        if old_hash is None:
                            # DBì— ì—†ìŒ â†’ ì‹ ê·œ CVE, ë°˜ë“œì‹œ ì²˜ë¦¬
                            result.append({"cve_id": cve_id, "is_new": True})
                            continue

                        # DBì— ìˆìŒ â†’ raw JSON ê°€ì ¸ì™€ì„œ í•´ì‹œ ë¹„êµ
                        raw_json = self._fetch_raw_cve_json(cve_id)
                        if raw_json is None:
                            continue
                        new_hash = self._compute_content_hash(raw_json)
                        if new_hash != old_hash:
                            result.append({"cve_id": cve_id, "is_new": False})
                        else:
                            skipped += 1
                else:
                    # DB ì—†ìœ¼ë©´ ë²Œí¬ ì»¤ë°‹ë„ ëª¨ë‘ ì²˜ë¦¬
                    for cve_id in bulk_cve_ids:
                        result.append({"cve_id": cve_id, "is_new": True})

            logger.info(f"ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ê²°ê³¼: {len(result)}ê±´ ì²˜ë¦¬ ëŒ€ìƒ "
                       f"(ì¼ë°˜ {len(normal_cve_ids)}ê±´, ë²Œí¬ {len(bulk_cve_ids)}ê±´ ì¤‘ {skipped}ê±´ ìŠ¤í‚µ)")
            return result

        except requests.exceptions.RequestException as e:
            logger.error(f"GitHub API error: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in fetch_recent_cves: {e}")
            return []
    
    def parse_affected(self, affected_list: List[Dict]) -> List[Dict]:
        """Affected ì •ë³´ íŒŒì‹±"""
        results = []
        
        for item in affected_list:
            vendor = item.get('vendor', 'Unknown')
            product = item.get('product', 'Unknown')
            versions = []
            patch_version = None
            
            for v in item.get('versions', []):
                version = v.get('version', '')
                less_than = v.get('lessThan', '')
                less_than_eq = v.get('lessThanOrEqual', '')
                ver_str = ""
                
                if v.get('status') == "affected":
                    if version and version not in ["0", "n/a"]:
                        ver_str += f"{version} ë¶€í„° "
                    if less_than:
                        ver_str += f"{less_than} ì´ì „"
                        patch_version = less_than  # ì´ ë²„ì „ ì´ìƒìœ¼ë¡œ íŒ¨ì¹˜
                    elif less_than_eq:
                        ver_str += f"{less_than_eq} ì´í•˜"
                        # lessThanOrEqualì€ ì •í™•í•œ íŒ¨ì¹˜ ë²„ì „ì„ ì•Œ ìˆ˜ ì—†ìŒ
                    elif not less_than and not less_than_eq and version:
                        ver_str = f"{version} (ë‹¨ì¼ ë²„ì „)"
                    
                    if not ver_str:
                        ver_str = "ëª¨ë“  ë²„ì „"
                    
                    versions.append(ver_str.strip())
                
                # unaffected/fixed ìƒíƒœì—ì„œ íŒ¨ì¹˜ ë²„ì „ ì¶”ì¶œ
                elif v.get('status') in ['unaffected', 'fixed'] and version:
                    if not patch_version:
                        patch_version = version
            
            results.append({
                "vendor": vendor,
                "product": product,
                "versions": ", ".join(versions) if versions else "ì •ë³´ ì—†ìŒ",
                "patch_version": patch_version
            })
        
        return results
    
    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=1, max=5)
    )
    def enrich_cve(self, cve_id: str) -> Dict:
        """CVE ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        try:
            rate_limit_manager.check_and_wait("github")
            
            parts = cve_id.split('-')
            year, id_num = parts[1], parts[2]
            group_dir = "0xxx" if len(id_num) < 4 else id_num[:-3] + "xxx"
            
            raw_url = f"https://raw.githubusercontent.com/CVEProject/cvelistV5/main/cves/{year}/{group_dir}/{cve_id}.json"
            
            response = requests.get(raw_url, timeout=10)
            response.raise_for_status()
            rate_limit_manager.record_call("github")
            
            json_data = response.json()
            cna = json_data.get('containers', {}).get('cna', {})

            # ì½˜í…ì¸  í•´ì‹œ ê³„ì‚° (DB ì €ì¥ìš©)
            content_hash = self._compute_content_hash(json_data)

            data = {
                "id": cve_id,
                "title": "N/A",
                "cvss": 0.0,
                "cvss_vector": "N/A",
                "description": "N/A",
                "state": "UNKNOWN",
                "cwe": [],
                "references": [],
                "affected": [],
                "content_hash": content_hash
            }
            
            data['state'] = json_data.get('cveMetadata', {}).get('state', 'UNKNOWN')
            data['title'] = cna.get('title', 'N/A')
            data['affected'] = self.parse_affected(cna.get('affected', []))
            
            for desc in cna.get('descriptions', []):
                if desc.get('lang') == 'en':
                    data['description'] = desc.get('value', 'N/A')
                    break
            
            for metric in cna.get('metrics', []):
                if 'cvssV4_0' in metric:
                    data['cvss'] = metric['cvssV4_0'].get('baseScore', 0.0)
                    data['cvss_vector'] = metric['cvssV4_0'].get('vectorString', 'N/A')
                    break
                elif 'cvssV3_1' in metric:
                    data['cvss'] = metric['cvssV3_1'].get('baseScore', 0.0)
                    data['cvss_vector'] = metric['cvssV3_1'].get('vectorString', 'N/A')
                    break
                elif 'cvssV3_0' in metric:
                    data['cvss'] = metric['cvssV3_0'].get('baseScore', 0.0)
                    data['cvss_vector'] = metric['cvssV3_0'].get('vectorString', 'N/A')
                    break
            
            for pt in cna.get('problemTypes', []):
                for desc in pt.get('descriptions', []):
                    cwe_id = desc.get('cweId', desc.get('description', ''))
                    if cwe_id:
                        data['cwe'].append(cwe_id)
            
            for ref in cna.get('references', []):
                if 'url' in ref:
                    data['references'].append(ref['url'])
            
            logger.debug(f"Enriched {cve_id}: CVSS={data['cvss']}, State={data['state']}")
            return data
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 404:
                logger.warning(f"{cve_id} not found (404)")
            else:
                logger.error(f"{cve_id} HTTP error: {e}")
            return self._error_response(cve_id)
        except Exception as e:
            logger.error(f"{cve_id} enrichment failed: {e}")
            return self._error_response(cve_id)
    
    # ====================================================================
    # [5] ì¶”ê°€ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ìˆ˜ì§‘
    # ====================================================================
    
    def fetch_vulncheck_kev(self) -> bool:
        """VulnCheck KEV ëª©ë¡ ë‹¤ìš´ë¡œë“œ (CISA KEVë³´ë‹¤ ì»¤ë²„ë¦¬ì§€ ë„“ìŒ)"""
        api_key = os.environ.get("VULNCHECK_API_KEY")
        if not api_key:
            logger.debug("VULNCHECK_API_KEY ë¯¸ì„¤ì •, VulnCheck KEV ê±´ë„ˆëœ€")
            return False
        
        try:
            rate_limit_manager.check_and_wait("vulncheck")
            
            response = requests.get(
                "https://api.vulncheck.com/v3/index/vulncheck-kev",
                headers={"Authorization": f"Bearer {api_key}", "Accept": "application/json"},
                timeout=15
            )
            response.raise_for_status()
            rate_limit_manager.record_call("vulncheck")
            
            data = response.json()
            for item in data.get('data', []):
                cve_id = item.get('cveID', '')
                if cve_id:
                    self.vulncheck_kev_set.add(cve_id)
            
            logger.info(f"VulnCheck KEV ë¡œë“œ: {len(self.vulncheck_kev_set)}ê±´")
            return True
            
        except Exception as e:
            logger.warning(f"VulnCheck KEV ì‹¤íŒ¨: {e}")
            return False
    
    def enrich_from_nvd(self, cve_data: Dict) -> Dict:
        """NVDì—ì„œ CVSS/CWE ë³´ì¶© (CVEProjectì— ì—†ì„ ë•Œ)"""
        api_key = os.environ.get("NVD_API_KEY")
        cve_id = cve_data['id']
        
        try:
            rate_limit_manager.check_and_wait("nvd")
            
            headers = {}
            if api_key:
                headers["apiKey"] = api_key
            
            response = requests.get(
                f"https://services.nvd.nist.gov/rest/json/cves/2.0?cveId={cve_id}",
                headers=headers, timeout=15
            )
            response.raise_for_status()
            rate_limit_manager.record_call("nvd")
            
            data = response.json()
            vulns = data.get('vulnerabilities', [])
            if not vulns:
                return cve_data
            
            cve_item = vulns[0].get('cve', {})
            metrics = cve_item.get('metrics', {})
            
            # CVSS ë³´ì¶© (ê¸°ì¡´ì— ì—†ì„ ë•Œë§Œ)
            if cve_data['cvss'] == 0.0:
                for key in ['cvssMetricV40', 'cvssMetricV31', 'cvssMetricV30']:
                    metric_list = metrics.get(key, [])
                    if metric_list:
                        cvss_data = metric_list[0].get('cvssData', {})
                        cve_data['cvss'] = cvss_data.get('baseScore', 0.0)
                        cve_data['cvss_vector'] = cvss_data.get('vectorString', 'N/A')
                        logger.info(f"  NVD CVSS ë³´ì¶©: {cve_id} â†’ {cve_data['cvss']}")
                        break
            
            # CWE ë³´ì¶© (ê¸°ì¡´ì— ì—†ì„ ë•Œë§Œ)
            if not cve_data['cwe']:
                for weakness in cve_item.get('weaknesses', []):
                    for desc in weakness.get('description', []):
                        cwe_val = desc.get('value', '')
                        if cwe_val and cwe_val != 'NVD-CWE-noinfo':
                            cve_data['cwe'].append(cwe_val)
            
            # CPE (ì˜í–¥ë°›ëŠ” ì œí’ˆ ì‹ë³„ì) ì¶”ê°€
            cpe_list = []
            for config in cve_item.get('configurations', []):
                for node in config.get('nodes', []):
                    for match in node.get('cpeMatch', []):
                        if match.get('vulnerable'):
                            cpe_list.append(match.get('criteria', ''))
            if cpe_list:
                cve_data['nvd_cpe'] = cpe_list[:5]
            
            return cve_data
            
        except Exception as e:
            logger.debug(f"NVD enrichment ì‹¤íŒ¨ ({cve_id}): {e}")
            return cve_data
    
    def check_poc_exists(self, cve_id: str) -> Dict:
        """PoC-in-GitHub í™•ì¸ (nomi-sec/PoC-in-GitHub)"""
        try:
            parts = cve_id.split('-')
            year = parts[1]
            
            rate_limit_manager.check_and_wait("github")
            
            url = f"https://raw.githubusercontent.com/nomi-sec/PoC-in-GitHub/master/{year}/{cve_id}.json"
            response = requests.get(url, timeout=10)
            rate_limit_manager.record_call("github")
            
            if response.status_code == 200:
                poc_data = response.json()
                poc_urls = []
                if isinstance(poc_data, list):
                    poc_urls = [p.get('html_url', '') for p in poc_data[:3] if p.get('html_url')]
                
                logger.info(f"  ğŸ”¥ PoC ë°œê²¬: {cve_id} ({len(poc_urls)}ê°œ)")
                return {"has_poc": True, "poc_count": len(poc_data) if isinstance(poc_data, list) else 1, "poc_urls": poc_urls}
            
            return {"has_poc": False, "poc_count": 0, "poc_urls": []}
            
        except Exception as e:
            logger.debug(f"PoC í™•ì¸ ì‹¤íŒ¨ ({cve_id}): {e}")
            return {"has_poc": False, "poc_count": 0, "poc_urls": []}
    
    def check_github_advisory(self, cve_id: str) -> Dict:
        """GitHub Advisory DBì—ì„œ íŒ¨í‚¤ì§€ ì •ë³´ ì¡°íšŒ"""
        try:
            rate_limit_manager.check_and_wait("github_advisory")
            
            response = requests.get(
                f"https://api.github.com/advisories?cve_id={cve_id}",
                headers=self.headers, timeout=10
            )
            response.raise_for_status()
            rate_limit_manager.record_call("github_advisory")
            
            advisories = response.json()
            if not advisories:
                return {"has_advisory": False}
            
            adv = advisories[0]
            packages = []
            for vuln in adv.get('vulnerabilities', []):
                pkg = vuln.get('package', {})
                if pkg:
                    packages.append({
                        "ecosystem": pkg.get('ecosystem', 'Unknown'),
                        "name": pkg.get('name', 'Unknown'),
                        "vulnerable_range": vuln.get('vulnerable_version_range', ''),
                        "patched": vuln.get('patched_versions', '')
                    })
            
            result = {
                "has_advisory": True,
                "severity": adv.get('severity', 'unknown'),
                "packages": packages[:5],
                "ghsa_id": adv.get('ghsa_id', '')
            }
            
            if packages:
                logger.info(f"  ğŸ“¦ GitHub Advisory ë°œê²¬: {cve_id} ({len(packages)}ê°œ íŒ¨í‚¤ì§€)")
            
            return result
            
        except Exception as e:
            logger.debug(f"GitHub Advisory ì‹¤íŒ¨ ({cve_id}): {e}")
            return {"has_advisory": False}
    
    def enrich_threat_intel(self, cve_data: Dict) -> Dict:
        """
        ì¶”ê°€ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ í†µí•© (NVD + PoC + VulnCheck + Advisory)
        enrich_cve() ì´í›„ì— í˜¸ì¶œ
        """
        cve_id = cve_data['id']
        logger.info(f"ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ìˆ˜ì§‘: {cve_id}")
        
        # 1. NVD CVSS/CWE ë³´ì¶©
        cve_data = self.enrich_from_nvd(cve_data)
        
        # 2. PoC ì¡´ì¬ ì—¬ë¶€
        poc_info = self.check_poc_exists(cve_id)
        cve_data['has_poc'] = poc_info['has_poc']
        cve_data['poc_count'] = poc_info['poc_count']
        cve_data['poc_urls'] = poc_info['poc_urls']
        
        # 3. VulnCheck KEV (ì´ë¯¸ fetchí•œ ì„¸íŠ¸ì—ì„œ ì¡°íšŒ)
        cve_data['is_vulncheck_kev'] = cve_id in self.vulncheck_kev_set
        
        # 4. GitHub Advisory
        advisory = self.check_github_advisory(cve_id)
        cve_data['github_advisory'] = advisory
        
        return cve_data
    
    def _error_response(self, cve_id: str) -> Dict:
        """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ"""
        return {
            "id": cve_id,
            "title": "Error",
            "cvss": 0.0,
            "cvss_vector": "N/A",
            "description": "Error",
            "state": "ERROR",
            "cwe": [],
            "references": [],
            "affected": []
        }