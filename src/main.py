import os
import datetime
import time
import requests
import pytz
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple, Optional
from google import genai
from google.genai import types
from logger import logger
from config import config
from collector import Collector
from database import ArgusDB
from notifier import SlackNotifier
from analyzer import Analyzer
from rule_manager import RuleManager
from rate_limiter import rate_limit_manager

# KST íƒ€ì„ì¡´ (í•œêµ­ í‘œì¤€ì‹œ)
KST = pytz.timezone('Asia/Seoul')

# Gemini í´ë¼ì´ì–¸íŠ¸ (í•œêµ­ì–´ ë²ˆì—­ìš©)
gemini_client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

# ==============================================================================
# [1] CVSS ë²¡í„° í•´ì„ ë§¤í•‘
# ==============================================================================
CVSS_MAP = {
    # ==========================================
    # [CVSS 3.1 Base Metrics]
    # ==========================================
    "AV:N": "ê³µê²© ê²½ë¡œ: ë„¤íŠ¸ì›Œí¬ (Network)", "AV:A": "ê³µê²© ê²½ë¡œ: ì¸ì ‘ (Adjacent)", "AV:L": "ê³µê²© ê²½ë¡œ: ë¡œì»¬ (Local)", "AV:P": "ê³µê²© ê²½ë¡œ: ë¬¼ë¦¬ì  (Physical)",
    "AC:L": "ë³µì¡ì„±: ë‚®ìŒ", "AC:H": "ë³µì¡ì„±: ë†’ìŒ",
    "PR:N": "í•„ìš” ê¶Œí•œ: ì—†ìŒ", "PR:L": "í•„ìš” ê¶Œí•œ: ë‚®ìŒ", "PR:H": "í•„ìš” ê¶Œí•œ: ë†’ìŒ",
    "UI:N": "ì‚¬ìš©ì ê´€ì—¬: ì—†ìŒ", "UI:R": "ì‚¬ìš©ì ê´€ì—¬: í•„ìˆ˜",
    "S:U": "ë²”ìœ„: ë³€ê²½ ì—†ìŒ", "S:C": "ë²”ìœ„: ë³€ê²½ë¨ (Changed)",
    "C:H": "ê¸°ë°€ì„±: ë†’ìŒ", "C:L": "ê¸°ë°€ì„±: ë‚®ìŒ", "C:N": "ê¸°ë°€ì„±: ì—†ìŒ",
    "I:H": "ë¬´ê²°ì„±: ë†’ìŒ", "I:L": "ë¬´ê²°ì„±: ë‚®ìŒ", "I:N": "ë¬´ê²°ì„±: ì—†ìŒ",
    "A:H": "ê°€ìš©ì„±: ë†’ìŒ", "A:L": "ê°€ìš©ì„±: ë‚®ìŒ", "A:N": "ê°€ìš©ì„±: ì—†ìŒ",

    # ==========================================
    # [CVSS 3.1 Temporal / Threat Metrics]
    # ==========================================
    "E:X": "ì•…ìš© ê°€ëŠ¥ì„±: ë¯¸ì •ì˜", "E:U": "ì•…ìš© ê°€ëŠ¥ì„±: ì…ì¦ ì•ˆë¨", "E:P": "ì•…ìš© ê°€ëŠ¥ì„±: ê°œë… ì¦ëª…(PoC)", "E:F": "ì•…ìš© ê°€ëŠ¥ì„±: ê¸°ëŠ¥ì ", "E:H": "ì•…ìš© ê°€ëŠ¥ì„±: ë†’ìŒ",
    "RL:X": "ëŒ€ì‘ ìˆ˜ì¤€: ë¯¸ì •ì˜", "RL:O": "ëŒ€ì‘ ìˆ˜ì¤€: ê³µì‹ íŒ¨ì¹˜", "RL:T": "ëŒ€ì‘ ìˆ˜ì¤€: ì„ì‹œ ìˆ˜ì •", "RL:W": "ëŒ€ì‘ ìˆ˜ì¤€: ìš°íšŒ ê°€ëŠ¥", "RL:U": "ëŒ€ì‘ ìˆ˜ì¤€: ì‚¬ìš© ë¶ˆê°€",
    "RC:X": "ë³´ê³  ì‹ ë¢°ë„: ë¯¸ì •ì˜", "RC:U": "ë³´ê³  ì‹ ë¢°ë„: ë¯¸í™•ì¸", "RC:R": "ë³´ê³  ì‹ ë¢°ë„: í•©ë¦¬ì ", "RC:C": "ë³´ê³  ì‹ ë¢°ë„: í™•ì¸ë¨",

    # ==========================================
    # [CVSS 3.1 Environmental Metrics]
    # ==========================================
    "MAV:N": "ìˆ˜ì •ëœ ê²½ë¡œ: ë„¤íŠ¸ì›Œí¬", "MAV:A": "ìˆ˜ì •ëœ ê²½ë¡œ: ì¸ì ‘", "MAV:L": "ìˆ˜ì •ëœ ê²½ë¡œ: ë¡œì»¬", "MAV:P": "ìˆ˜ì •ëœ ê²½ë¡œ: ë¬¼ë¦¬ì ",
    "MAC:L": "ìˆ˜ì •ëœ ë³µì¡ì„±: ë‚®ìŒ", "MAC:H": "ìˆ˜ì •ëœ ë³µì¡ì„±: ë†’ìŒ",
    "MPR:N": "ìˆ˜ì •ëœ ê¶Œí•œ: ì—†ìŒ", "MPR:L": "ìˆ˜ì •ëœ ê¶Œí•œ: ë‚®ìŒ", "MPR:H": "ìˆ˜ì •ëœ ê¶Œí•œ: ë†’ìŒ",
    "MUI:N": "ìˆ˜ì •ëœ ê´€ì—¬: ì—†ìŒ", "MUI:R": "ìˆ˜ì •ëœ ê´€ì—¬: í•„ìˆ˜",
    "MS:U": "ìˆ˜ì •ëœ ë²”ìœ„: ë³€ê²½ ì—†ìŒ", "MS:C": "ìˆ˜ì •ëœ ë²”ìœ„: ë³€ê²½ë¨",
    "MC:H": "ìˆ˜ì •ëœ ê¸°ë°€ì„±: ë†’ìŒ", "MC:L": "ìˆ˜ì •ëœ ê¸°ë°€ì„±: ë‚®ìŒ", "MC:N": "ìˆ˜ì •ëœ ê¸°ë°€ì„±: ì—†ìŒ",
    "MI:H": "ìˆ˜ì •ëœ ë¬´ê²°ì„±: ë†’ìŒ", "MI:L": "ìˆ˜ì •ëœ ë¬´ê²°ì„±: ë‚®ìŒ", "MI:N": "ìˆ˜ì •ëœ ë¬´ê²°ì„±: ì—†ìŒ",
    "MA:H": "ìˆ˜ì •ëœ ê°€ìš©ì„±: ë†’ìŒ", "MA:L": "ìˆ˜ì •ëœ ê°€ìš©ì„±: ë‚®ìŒ", "MA:N": "ìˆ˜ì •ëœ ê°€ìš©ì„±: ì—†ìŒ",
    "CR:X": "ê¸°ë°€ì„± ìš”êµ¬: ë¯¸ì •ì˜", "CR:L": "ê¸°ë°€ì„± ìš”êµ¬: ë‚®ìŒ", "CR:M": "ê¸°ë°€ì„± ìš”êµ¬: ë³´í†µ", "CR:H": "ê¸°ë°€ì„± ìš”êµ¬: ë†’ìŒ",
    "IR:X": "ë¬´ê²°ì„± ìš”êµ¬: ë¯¸ì •ì˜", "IR:L": "ë¬´ê²°ì„± ìš”êµ¬: ë‚®ìŒ", "IR:M": "ë¬´ê²°ì„± ìš”êµ¬: ë³´í†µ", "IR:H": "ë¬´ê²°ì„± ìš”êµ¬: ë†’ìŒ",
    "AR:X": "ê°€ìš©ì„± ìš”êµ¬: ë¯¸ì •ì˜", "AR:L": "ê°€ìš©ì„± ìš”êµ¬: ë‚®ìŒ", "AR:M": "ê°€ìš©ì„± ìš”êµ¬: ë³´í†µ", "AR:H": "ê°€ìš©ì„± ìš”êµ¬: ë†’ìŒ",

    # ==========================================
    # [CVSS 4.0 Base Metrics]
    # ==========================================
    "AT:N": "ê³µê²© ê¸°ìˆ : ì—†ìŒ", "AT:P": "ê³µê²© ê¸°ìˆ : ì¡´ì¬(Present)",
    "VC:H": "ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë†’ìŒ", "VC:L": "ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë‚®ìŒ", "VC:N": "ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ì—†ìŒ",
    "VI:H": "ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë†’ìŒ", "VI:L": "ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë‚®ìŒ", "VI:N": "ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ì—†ìŒ",
    "VA:H": "ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë†’ìŒ", "VA:L": "ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë‚®ìŒ", "VA:N": "ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ì—†ìŒ",
    "SC:H": "í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë†’ìŒ", "SC:L": "í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë‚®ìŒ", "SC:N": "í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ì—†ìŒ",
    "SI:H": "í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë†’ìŒ", "SI:L": "í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë‚®ìŒ", "SI:N": "í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ì—†ìŒ",
    "SA:H": "í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë†’ìŒ", "SA:L": "í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë‚®ìŒ", "SA:N": "í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ì—†ìŒ",

    # ==========================================
    # [CVSS 4.0 Environmental (Modified Base) Metrics]
    # ==========================================
    "MAT:N": "ìˆ˜ì •ëœ ê³µê²© ê¸°ìˆ : ì—†ìŒ", "MAT:P": "ìˆ˜ì •ëœ ê³µê²© ê¸°ìˆ : ì¡´ì¬",
    "MVC:H": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë†’ìŒ", "MVC:L": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë‚®ìŒ", "MVC:N": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ì—†ìŒ",
    "MVI:H": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë†’ìŒ", "MVI:L": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë‚®ìŒ", "MVI:N": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ì—†ìŒ",
    "MVA:H": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë†’ìŒ", "MVA:L": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë‚®ìŒ", "MVA:N": "ìˆ˜ì •ëœ ì·¨ì•½ì‹œìŠ¤í…œ ê°€ìš©ì„±: ì—†ìŒ",
    "MSC:H": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë†’ìŒ", "MSC:L": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ë‚®ìŒ", "MSC:N": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ì—†ìŒ", "MSC:S": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê¸°ë°€ì„±: ì•ˆì „(Safety)",
    "MSI:H": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë†’ìŒ", "MSI:L": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ë‚®ìŒ", "MSI:N": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ì—†ìŒ", "MSI:S": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ë¬´ê²°ì„±: ì•ˆì „(Safety)",
    "MSA:H": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë†’ìŒ", "MSA:L": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ë‚®ìŒ", "MSA:N": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ì—†ìŒ", "MSA:S": "ìˆ˜ì •ëœ í›„ì†ì‹œìŠ¤í…œ ê°€ìš©ì„±: ì•ˆì „(Safety)",

    # ==========================================
    # [CVSS 4.0 Supplemental Metrics]
    # ==========================================
    "S:X": "ì•ˆì „(Safety): ë¯¸ì •ì˜", "S:N": "ì•ˆì „(Safety): ë¬´ì‹œ ê°€ëŠ¥", "S:P": "ì•ˆì „(Safety): ì¡´ì¬(Present)",
    "AU:X": "ìë™í™” ê°€ëŠ¥ì„±: ë¯¸ì •ì˜", "AU:N": "ìë™í™” ê°€ëŠ¥ì„±: ì•„ë‹ˆì˜¤", "AU:Y": "ìë™í™” ê°€ëŠ¥ì„±: ì˜ˆ",
    "R:X": "ë³µêµ¬(Recovery): ë¯¸ì •ì˜", "R:A": "ë³µêµ¬: ìë™", "R:U": "ë³µêµ¬: ì‚¬ìš©ì", "R:I": "ë³µêµ¬: ë³µêµ¬ ë¶ˆê°€",
    "V:X": "ê°€ì¹˜ ë°€ë„: ë¯¸ì •ì˜", "V:D": "ê°€ì¹˜ ë°€ë„: ë¶„ì‚°(Diffuse)", "V:C": "ê°€ì¹˜ ë°€ë„: ì§‘ì¤‘(Concentrated)",
    "RE:X": "ëŒ€ì‘ ë…¸ë ¥: ë¯¸ì •ì˜", "RE:L": "ëŒ€ì‘ ë…¸ë ¥: ë‚®ìŒ", "RE:M": "ëŒ€ì‘ ë…¸ë ¥: ë³´í†µ", "RE:H": "ëŒ€ì‘ ë…¸ë ¥: ë†’ìŒ",
    "U:X": "ê¸´ê¸‰ì„±: ë¯¸ì •ì˜", "U:Clear": "ê¸´ê¸‰ì„±: ëª…í™•í•¨", "U:Green": "ê¸´ê¸‰ì„±: ë‚®ìŒ(Green)", "U:Amber": "ê¸´ê¸‰ì„±: ì£¼ì˜(Amber)", "U:Red": "ê¸´ê¸‰ì„±: ë†’ìŒ(Red)"
}

# ==============================================================================
# [2] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================================================

def parse_cvss_vector(vector_str: str) -> str:
    if not vector_str or vector_str == "N/A":
        return "ì •ë³´ ì—†ìŒ"
    
    parts = vector_str.split('/')
    mapped_parts = []
    
    for part in parts:
        if ':' in part:
            full_key = part
            desc = CVSS_MAP.get(full_key, f"**{part}**")
            if full_key in CVSS_MAP:
                mapped_parts.append(f"â€¢ {desc}")
            else:
                mapped_parts.append(f"â€¢ {part}")
    
    return "<br>".join(mapped_parts)

def is_target_asset(cve_data: Dict, cve_id: str) -> Tuple[bool, Optional[str]]:
    for target in config.get_target_assets():
        t_vendor = target.get('vendor', '').lower()
        t_product = target.get('product', '').lower()

        # ì „ì²´ ê°ì‹œ ëª¨ë“œ
        if t_vendor == "*" and t_product == "*":
            return True, "All Assets (*)"

        # 1ì°¨: affected í•„ë“œì˜ êµ¬ì¡°í™”ëœ vendor/product ë§¤ì¹­
        for affected in cve_data.get('affected', []):
            a_vendor = affected.get('vendor', '').lower()
            a_product = affected.get('product', '').lower()

            # vendorê°€ N/A, Unknownì´ë©´ ê±´ë„ˆë›°ê¸° (2ì°¨ì—ì„œ descriptionìœ¼ë¡œ í™•ì¸)
            if a_vendor in ('', 'unknown', 'n/a'):
                continue

            vendor_match = (t_vendor in a_vendor) or (a_vendor in t_vendor)
            product_match = (t_product == "*") or (t_product in a_product) or (a_product in t_product)

            if vendor_match and product_match:
                return True, f"Matched (affected): {a_vendor}/{a_product}"

        # 2ì°¨(ë³´ì¡°): description í…ìŠ¤íŠ¸ ë§¤ì¹­
        # affectedì— ì •ë³´ê°€ ì—†ê±°ë‚˜ N/Aì¸ ê²½ìš°ë¥¼ ìœ„í•œ fallback
        desc_lower = cve_data.get('description', '').lower()
        if desc_lower and t_vendor in desc_lower and (t_product == "*" or t_product in desc_lower):
            return True, f"Matched (description): {t_vendor}/{t_product}"

    return False, None

def generate_korean_summary(cve_data: Dict) -> Tuple[str, str]:
    prompt = f"""
Task: Translate Title and Summarize Description into Korean.
[Input] Title: {cve_data['title']} / Desc: {cve_data['description']}
[Format]
ì œëª©: [Korean Title]
ë‚´ìš©: [Korean Summary (Max 3 lines)]
Do NOT add intro/outro.
"""
    
    try:
        rate_limit_manager.check_and_wait("gemini")
        response = gemini_client.models.generate_content(
            model=config.MODEL_PHASE_0,
            contents=prompt,
            config=types.GenerateContentConfig(
                safety_settings=[types.SafetySetting(
                    category="HARM_CATEGORY_DANGEROUS_CONTENT",
                    threshold="BLOCK_NONE"
                )]
            )
        )
        rate_limit_manager.record_call("gemini")

        text = response.text.strip()
        title_ko, desc_ko = cve_data['title'], cve_data['description'][:200]
        
        for line in text.split('\n'):
            if line.startswith("ì œëª©:"):
                title_ko = line.replace("ì œëª©:", "").strip()
            if line.startswith("ë‚´ìš©:"):
                desc_ko = line.replace("ë‚´ìš©:", "").strip()
        
        return title_ko, desc_ko
        
    except Exception as e:
        logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨: {e}, ì›ë³¸ ì‚¬ìš©")
        return cve_data['title'], cve_data['description'][:200]

# ==============================================================================
# [3] GitHub Issue ìƒì„±/ì—…ë°ì´íŠ¸
# ==============================================================================

def create_github_issue(cve_data: Dict, reason: str) -> Tuple[Optional[str], Optional[Dict]]:
    token = os.environ.get("GH_TOKEN")
    repo = os.environ.get("GITHUB_REPOSITORY")
    
    if not repo:
        logger.warning("GITHUB_REPOSITORY ë¯¸ì„¤ì •, Issue ìƒì„± ê±´ë„ˆëœ€")
        return None, None
    
    try:
        # Step 1: AI ë¶„ì„
        logger.info(f"AI ë¶„ì„ ì‹œì‘: {cve_data['id']}")
        analyzer = Analyzer()
        analysis = analyzer.analyze_cve(cve_data)
        
        # Step 2: ë£° ìƒì„±/ìˆ˜ì§‘
        logger.info(f"ë£° ìˆ˜ì§‘ ì‹œì‘: {cve_data['id']}")
        rule_manager = RuleManager()
        rules = rule_manager.get_rules(cve_data, analysis)
        
        # Step 3: ê³µì‹ ë£° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        has_official = any([
            rules.get('sigma') and rules['sigma'].get('verified'),
            any(r.get('verified') for r in rules.get('network', [])),  # networkëŠ” ë¦¬ìŠ¤íŠ¸!
            rules.get('yara') and rules['yara'].get('verified')
        ])
        
        # Step 4: ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ êµ¬ì„±
        body = _build_issue_body(cve_data, reason, analysis, rules, has_official)
        
        # Step 5: GitHub API í˜¸ì¶œ
        url = f"https://api.github.com/repos/{repo}/issues"
        headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json"
        }
        payload = {
            "title": f"[Argus] {cve_data['id']}: {cve_data['title_ko']}",
            "body": body,
            "labels": ["security", "cve"]
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        response.raise_for_status()
        
        issue_url = response.json().get("html_url")
        logger.info(f"GitHub Issue ìƒì„± ì„±ê³µ: {issue_url}")
        
        return issue_url, {"has_official": has_official, "rules": rules}
        
    except Exception as e:
        logger.error(f"GitHub Issue ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None

def _build_issue_body(cve_data: Dict, reason: str, analysis: Dict, rules: Dict, has_official: bool) -> str:
    # CVSS ë°°ì§€ ìƒ‰ìƒ
    score = cve_data['cvss']
    if score >= 9.0: color = "FF0000"
    elif score >= 7.0: color = "FD7E14"
    elif score >= 4.0: color = "FFC107"
    elif score > 0: color = "28A745"
    else: color = "CCCCCC"
    
    kev_color = "FF0000" if cve_data['is_kev'] else "CCCCCC"
    
    badges = f"![CVSS](https://img.shields.io/badge/CVSS-{score}-{color}) ![EPSS](https://img.shields.io/badge/EPSS-{cve_data['epss']*100:.2f}%25-blue) ![KEV](https://img.shields.io/badge/KEV-{'YES' if cve_data['is_kev'] else 'No'}-{kev_color})"
    
    cwe_str = ", ".join(cve_data['cwe']) if cve_data['cwe'] else "N/A"
    
    # ì˜í–¥ë°›ëŠ” ìì‚° í…Œì´ë¸”
    affected_rows = ""
    for item in cve_data.get('affected', []):
        affected_rows += f"| {item['vendor']} | {item['product']} | {item['versions']} |\n"
    if not affected_rows:
        affected_rows = "| - | - | - |"
    
    # ëŒ€ì‘ ë°©ì•ˆ
    mitigation_list = "\n".join([f"- {m}" for m in analysis.get('mitigation', [])])
    
    # ì°¸ê³  ìë£Œ
    ref_list = "\n".join([f"- {r}" for r in cve_data['references']])
    
    # CVSS ë²¡í„° í•´ì„
    vector_details = parse_cvss_vector(cve_data.get('cvss_vector', 'N/A'))
    
    # ë£° ì„¹ì…˜
    rules_section = ""
    has_any_rules = rules.get('sigma') or rules.get('network') or rules.get('yara')
    
    if has_any_rules:
        rules_section = "## ğŸ›¡ï¸ AI ìƒì„± íƒì§€ ë£°\n\n"
        
        if not has_official:
            rules_section += "> âš ï¸ **ì£¼ì˜:** AI ìƒì„± ë£°ì€ ì‹¤ì œ ë°°í¬ ì „ ë³´ì•ˆ ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\n"
        
        # Sigma ë£°
        if rules.get('sigma'):
            is_verified = rules['sigma'].get('verified')
            badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
            
            # AI ìƒì„± ë£°ì´ë©´ ì§€í‘œ ì •ë³´ í‘œì‹œ
            indicator_info = ""
            if not is_verified and rules['sigma'].get('indicators'):
                indicators = rules['sigma']['indicators']
                if indicators:
                    indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
            
            rules_section += f"### Sigma Rule ({rules['sigma']['source']}) {badge}\n{indicator_info}```yaml\n{rules['sigma']['code']}\n```\n\n"
        
        # ë„¤íŠ¸ì›Œí¬ ë£° (Snort/Suricata - ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
        if rules.get('network'):
            for idx, net_rule in enumerate(rules['network'], 1):
                is_verified = net_rule.get('verified')
                badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
                engine_name = net_rule.get('engine', 'unknown').upper()
                
                # AI ìƒì„± ë£°ì´ë©´ ì§€í‘œ ì •ë³´ í‘œì‹œ
                indicator_info = ""
                if not is_verified and net_rule.get('indicators'):
                    indicators = net_rule['indicators']
                    if indicators:
                        indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
                
                rules_section += f"### Network Rule #{idx} ({net_rule['source']} - {engine_name}) {badge}\n{indicator_info}```bash\n{net_rule['code']}\n```\n\n"
        
        # Yara ë£°
        if rules.get('yara'):
            is_verified = rules['yara'].get('verified')
            badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
            
            # AI ìƒì„± ë£°ì´ë©´ ì§€í‘œ ì •ë³´ í‘œì‹œ
            indicator_info = ""
            if not is_verified and rules['yara'].get('indicators'):
                indicators = rules['yara']['indicators']
                if indicators:
                    indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
            
            rules_section += f"### Yara Rule ({rules['yara']['source']}) {badge}\n{indicator_info}```yara\n{rules['yara']['code']}\n```\n\n"
    
    # íƒì§€ ë£° í˜„í™© ì„¹ì…˜ (í•­ìƒ í‘œì‹œ)
    skip_reasons = rules.get('skip_reasons', {})
    ai_status_section = "## ğŸ“‹ íƒì§€ ë£° í˜„í™©\n\n"

    # Sigma ìƒíƒœ
    if rules.get('sigma'):
        if rules['sigma'].get('verified'):
            ai_status_section += "**Sigma Rule** âœ… ê³µì‹ ë£° ë°œê²¬\n\n"
        else:
            ai_status_section += "**Sigma Rule** âœ… AI ìƒì„± ì™„ë£Œ\n\n"
    else:
        skip_reason = skip_reasons.get('sigma', 'ê³µê°œ ë£° ë¯¸ë°œê²¬, AI ìƒì„± ì‹¤íŒ¨')
        ai_status_section += f"**Sigma Rule** âŒ ë¯¸ìƒì„±\n> **ì‚¬ìœ :** {skip_reason}\n\n"

    # Snort/Suricata ìƒíƒœ
    if rules.get('network'):
        verified_count = sum(1 for r in rules['network'] if r.get('verified'))
        if verified_count > 0:
            ai_status_section += f"**Snort/Suricata Rule** âœ… ê³µì‹ ë£° ë°œê²¬ ({verified_count}ê°œ ì—”ì§„)\n\n"
        else:
            ai_status_section += "**Snort/Suricata Rule** âœ… AI ìƒì„± ì™„ë£Œ\n\n"
    else:
        skip_reason = skip_reasons.get('network', 'ê³µê°œ ë£° ë¯¸ë°œê²¬, AI ìƒì„± ì‹¤íŒ¨')
        ai_status_section += f"**Snort/Suricata Rule** âŒ ë¯¸ìƒì„±\n> **ì‚¬ìœ :** {skip_reason}\n\n"

    # Yara ìƒíƒœ
    if rules.get('yara'):
        if rules['yara'].get('verified'):
            ai_status_section += "**Yara Rule** âœ… ê³µì‹ ë£° ë°œê²¬\n\n"
        else:
            ai_status_section += "**Yara Rule** âœ… AI ìƒì„± ì™„ë£Œ\n\n"
    else:
        skip_reason = skip_reasons.get('yara', 'ê³µê°œ ë£° ë¯¸ë°œê²¬, AI ìƒì„± ì‹¤íŒ¨')
        ai_status_section += f"**Yara Rule** âŒ ë¯¸ìƒì„±\n> **ì‚¬ìœ :** {skip_reason}\n\n"
    
    now_kst = datetime.datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S (KST)')
    
    body = f"""# ğŸ›¡ï¸ {cve_data['title_ko']}

> **íƒì§€ ì¼ì‹œ:** {now_kst}
> **íƒì§€ ì‚¬ìœ :** {reason}

{badges}
**ì·¨ì•½ì  ìœ í˜• (CWE):** {cwe_str}

## ğŸ“¦ ì˜í–¥ ë°›ëŠ” ìì‚°
| ë²¤ë” | ì œí’ˆ | ë²„ì „ |
| :--- | :--- | :--- |
{affected_rows}

## ğŸ” AI ì‹¬ì¸µ ë¶„ì„
| í•­ëª© | ë‚´ìš© |
| :--- | :--- |
| **ê¸°ìˆ ì  ì›ì¸** | {analysis.get('root_cause', '-')} |
| **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥** | {analysis.get('impact', '-')} |

### ğŸ¹ ê³µê²© ë²¡í„° ìƒì„¸
| í•­ëª© | ë‚´ìš© |
| :--- | :--- |
| **ê³µì‹ ë²¡í„°** | `{cve_data.get('cvss_vector', 'N/A')}` |
| **ìƒì„¸ ë¶„ì„** | {vector_details} |

### ğŸ¹ AI ì˜ˆìƒ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤
> {analysis.get('scenario', 'ì •ë³´ ì—†ìŒ')}

## ğŸ›¡ï¸ AI ê¶Œê³  ëŒ€ì‘ ë°©ì•ˆ
{mitigation_list}

{rules_section}
{ai_status_section}

## ğŸ”— ì°¸ê³  ìë£Œ
{ref_list}
"""
    return body.strip()

def update_github_issue_with_official_rules(issue_url: str, cve_id: str, rules: Dict) -> bool:
    comment = f"""## âœ… ê³µì‹ íƒì§€ ë£° ë°œê²¬

{cve_id}ì— ëŒ€í•œ **ê³µì‹ ê²€ì¦ëœ íƒì§€ ë£°**ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. AI ìƒì„± ë£°ì„ ì´ê²ƒìœ¼ë¡œ êµì²´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

"""
    
    # Sigma
    if rules.get('sigma') and rules['sigma'].get('verified'):
        comment += f"### Sigma Rule ({rules['sigma']['source']})\n```yaml\n{rules['sigma']['code']}\n```\n\n"
    
    # Network (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
    if rules.get('network'):
        for idx, net_rule in enumerate(rules['network'], 1):
            if net_rule.get('verified'):
                engine = net_rule.get('engine', 'unknown').upper()
                comment += f"### Network Rule #{idx} ({net_rule['source']} - {engine})\n```bash\n{net_rule['code']}\n```\n\n"
    
    # Yara
    if rules.get('yara') and rules['yara'].get('verified'):
        comment += f"### Yara Rule ({rules['yara']['source']})\n```yara\n{rules['yara']['code']}\n```\n\n"
    
    notifier = SlackNotifier()
    return notifier.update_github_issue(issue_url, comment)

# ==============================================================================
# [4] CVE ì²˜ë¦¬ (ë‹¨ì¼)
# ==============================================================================

def process_single_cve(cve_id: str, collector: Collector, db: ArgusDB, notifier: SlackNotifier) -> Optional[Dict]:
    try:
        # Step 1: CVE ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        raw_data = collector.enrich_cve(cve_id)
        
        if raw_data.get('state') != 'PUBLISHED':
            logger.debug(f"{cve_id}: PUBLISHED ìƒíƒœ ì•„ë‹˜, ê±´ë„ˆëœ€")
            return None
        
        # Step 2: ìì‚° í•„í„°ë§ (affected vendor/product ìš°ì„ , description ë³´ì¡°)
        is_target, match_info = is_target_asset(raw_data, cve_id)
        if not is_target:
            logger.debug(f"{cve_id}: ê°ì‹œ ëŒ€ìƒ ì•„ë‹˜, ê±´ë„ˆëœ€")
            return None

        # Step 2.5: ì¶”ê°€ ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ (NVD, PoC, VulnCheck, Advisory)
        raw_data = collector.enrich_threat_intel(raw_data)

        # Step 3: í˜„ì¬ ìƒíƒœ êµ¬ì„±
        current_state = {
            "id": cve_id,
            "title": raw_data['title'],
            "cvss": raw_data['cvss'],
            "cvss_vector": raw_data['cvss_vector'],
            "is_kev": cve_id in collector.kev_set,
            "epss": collector.epss_cache.get(cve_id, 0.0),
            "description": raw_data['description'],
            "cwe": raw_data['cwe'],
            "references": raw_data['references'],
            "affected": raw_data['affected'],
            "has_poc": raw_data.get('has_poc', False),
            "poc_count": raw_data.get('poc_count', 0),
            "poc_urls": raw_data.get('poc_urls', []),
            "is_vulncheck_kev": raw_data.get('is_vulncheck_kev', False),
            "github_advisory": raw_data.get('github_advisory', {}),
            "nvd_cpe": raw_data.get('nvd_cpe', [])
        }
        
        # Step 4: ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨
        last_record = db.get_cve(cve_id)
        last_state = last_record.get('last_alert_state') if last_record else None
        
        should_alert, alert_reason, is_high_risk = _should_send_alert(
            current_state, last_state
        )
        
        if not should_alert:
            # ì•Œë¦¼ ë¶ˆí•„ìš”, DBë§Œ ì—…ë°ì´íŠ¸ (content_hashë„ ê°±ì‹ )
            db.upsert_cve({
                "id": cve_id,
                "updated_at": datetime.datetime.now(KST).isoformat(),
                "content_hash": raw_data.get('content_hash')
            })
            return None
        
        # Step 5: í•œêµ­ì–´ ë²ˆì—­
        logger.info(f"ì•Œë¦¼ ë°œì†¡ ì¤€ë¹„: {cve_id} (HighRisk: {is_high_risk})")
        title_ko, desc_ko = generate_korean_summary(current_state)
        current_state['title_ko'] = title_ko
        current_state['desc_ko'] = desc_ko
        
        # Step 6: High Riskë©´ GitHub Issue ìƒì„±
        report_url = None
        rules_info = None
        if is_high_risk:
            report_url, rules_info = create_github_issue(current_state, alert_reason)
        
        # Step 7: Slack ì•Œë¦¼
        notifier.send_alert(current_state, alert_reason, report_url)
        
        # Step 8: DB ì €ì¥ (content_hash í¬í•¨)
        db_data = {
            "id": cve_id,
            "cvss_score": current_state['cvss'],
            "epss_score": current_state['epss'],
            "is_kev": current_state['is_kev'],
            "last_alert_at": datetime.datetime.now(KST).isoformat(),
            "last_alert_state": current_state,
            "report_url": report_url,
            "updated_at": datetime.datetime.now(KST).isoformat(),
            "content_hash": raw_data.get('content_hash')
        }
        
        if rules_info:
            db_data["has_official_rules"] = rules_info.get('has_official', False)
            db_data["rules_snapshot"] = rules_info.get('rules')
            db_data["last_rule_check_at"] = datetime.datetime.now(KST).isoformat()
        
        db.upsert_cve(db_data)
        
        return {"cve_id": cve_id, "status": "success"}
        
    except Exception as e:
        logger.error(f"{cve_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        return None

def _should_send_alert(current: Dict, last: Optional[Dict]) -> Tuple[bool, str, bool]:
    is_high_risk = current['cvss'] >= 7.0 or current['is_kev']
    
    # ì‹ ê·œ CVE
    if last is None:
        return True, "ì‹ ê·œ ì·¨ì•½ì ", is_high_risk
    
    # KEV ë“±ì¬
    if current['is_kev'] and not last.get('is_kev'):
        return True, "ğŸš¨ KEV ë“±ì¬", True
    
    # EPSS ê¸‰ì¦
    if current['epss'] >= 0.1 and (current['epss'] - last.get('epss', 0)) > 0.05:
        return True, "ğŸ“ˆ EPSS ê¸‰ì¦", True
    
    # CVSS ìƒí–¥
    if current['cvss'] >= 7.0 and last.get('cvss', 0) < 7.0:
        return True, "ğŸ”º CVSS ìœ„í—˜ë„ ìƒí–¥", True
    
    return False, "", is_high_risk

# ==============================================================================
# [5] ê³µì‹ ë£° ì¬ë°œê²¬
# ==============================================================================

def check_for_official_rules() -> None:
    """
    ê³µì‹ ë£° ì¬ë°œê²¬ ì²´í¬.

    ëŒ€ìƒ:
    1. AI ë£°ë§Œ ìˆëŠ” CVE â†’ ê³µì‹ ë£°ë¡œ êµì²´
    2. ë£°ì´ ì•„ì˜ˆ ì—†ëŠ” ê³ ìœ„í—˜ CVE (CVSS >= 7.0, KEV) â†’ ìƒˆë¡œ ë‚˜ì˜¨ ê³µì‹ ë£° ì ìš©
    3. ë£° ì—†ì´ AI ìƒì„±ë„ ì‹¤íŒ¨í•œ CVE â†’ ì¬ì‹œë„

    ë°°ì¹˜ ì œí•œ: config ê¸°ë°˜ (ê¸°ë³¸ 10ê±´)
    ì¿¨ë‹¤ìš´: ì„±ê³µ 7ì¼ / ì‹¤íŒ¨ 1ì¼ (ë¹ ë¥¸ ì¬ì‹œë„)
    """
    try:
        logger.info("=== ê³µì‹ ë£° ì¬ë°œê²¬ ì²´í¬ ì‹œì‘ ===")

        db = ArgusDB()
        notifier = SlackNotifier()
        rule_manager = RuleManager()

        candidates = db.get_ai_generated_cves()

        if not candidates:
            logger.info("ì¬í™•ì¸ ëŒ€ìƒ ì—†ìŒ")
            return

        # ë°°ì¹˜ ì œí•œ: config ê¸°ë°˜ (2ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ Ã— 10ê±´ = í•˜ë£¨ 120ê±´ ì²˜ë¦¬ ê°€ëŠ¥)
        max_recheck = config.PERFORMANCE.get("max_rule_recheck", 10)
        if len(candidates) > max_recheck:
            logger.info(f"ì¬í™•ì¸ ëŒ€ìƒ: {len(candidates)}ê±´ ì¤‘ {max_recheck}ê±´ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)")
            candidates = candidates[:max_recheck]
        else:
            logger.info(f"ì¬í™•ì¸ ëŒ€ìƒ: {len(candidates)}ê±´")

        found_count = 0

        for record in candidates:
            cve_id = record['id']

            try:
                # ê³µê°œ ë£°ë§Œ ê²€ìƒ‰
                rules = rule_manager.search_public_only(cve_id)

                # ê³µì‹ ë£° ì¡´ì¬ í™•ì¸
                has_official = any([
                    rules.get('sigma') and rules['sigma'].get('verified'),
                    any(r.get('verified') for r in rules.get('network', [])),
                    rules.get('yara') and rules['yara'].get('verified')
                ])

                now_iso = datetime.datetime.now(KST).isoformat()

                if has_official:
                    found_count += 1
                    logger.info(f"âœ… {cve_id}: ê³µì‹ ë£° ë°œê²¬!")

                    # Slack ì•Œë¦¼
                    title_ko = record.get('last_alert_state', {}).get('title_ko', cve_id)
                    notifier.send_official_rule_update(
                        cve_id=cve_id,
                        title=title_ko,
                        rules_info=rules,
                        original_report_url=record.get('report_url')
                    )

                    # GitHub Issue ì—…ë°ì´íŠ¸
                    if record.get('report_url'):
                        update_github_issue_with_official_rules(
                            record['report_url'],
                            cve_id,
                            rules
                        )

                    # DB ì—…ë°ì´íŠ¸ â€” ê³µì‹ ë£° ë°œê²¬ (ì‹¤íŒ¨ í”Œë˜ê·¸ ì´ˆê¸°í™”)
                    db.upsert_cve({
                        "id": cve_id,
                        "has_official_rules": True,
                        "rules_snapshot": rules,
                        "last_rule_check_at": now_iso,
                        "last_rule_check_failed": False,
                        "updated_at": now_iso
                    })
                else:
                    # ê³µì‹ ë£° ë¯¸ë°œê²¬ â€” ì¿¨ë‹¤ìš´ ê°±ì‹  (7ì¼ í›„ ì¬í™•ì¸)
                    db.upsert_cve({
                        "id": cve_id,
                        "last_rule_check_at": now_iso,
                        "last_rule_check_failed": False,
                        "updated_at": now_iso
                    })

            except Exception as e:
                logger.error(f"{cve_id} ê³µì‹ ë£° ì²´í¬ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ì¿¨ë‹¤ìš´ 1ì¼ (ë¹ ë¥¸ ì¬ì‹œë„)
                try:
                    db.upsert_cve({
                        "id": cve_id,
                        "last_rule_check_at": datetime.datetime.now(KST).isoformat(),
                        "last_rule_check_failed": True,
                        "updated_at": datetime.datetime.now(KST).isoformat()
                    })
                except Exception:
                    pass
                continue

        logger.info(f"=== ê³µì‹ ë£° ì¬ë°œê²¬ ì²´í¬ ì™„ë£Œ (ë°œê²¬: {found_count}ê±´) ===")

    except Exception as e:
        logger.error(f"ê³µì‹ ë£° ì²´í¬ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [6] ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ==============================================================================

def main():
    start_time = time.time()
    logger.info("=" * 60)
    logger.info(f"Argus Phase 1 ì‹œì‘ (Model: {config.MODEL_PHASE_1})")
    logger.info("=" * 60)
    
    # Step 1: í—¬ìŠ¤ì²´í¬
    health = config.health_check()
    if not all(health.values()):
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {health}")
        return
    logger.info(f"âœ… í—¬ìŠ¤ì²´í¬ í†µê³¼: {health}")
    
    # Step 2: ëª¨ë“ˆ ì´ˆê¸°í™”
    collector = Collector()
    db = ArgusDB()
    notifier = SlackNotifier()
    
    # Step 3: ê³µì‹ ë£° ì¬ë°œê²¬
    check_for_official_rules()
    
    # Step 4: KEV ë° ìµœì‹  CVE ìˆ˜ì§‘ (ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ì ìš©)
    collector.fetch_kev()
    collector.fetch_vulncheck_kev()
    target_cves = collector.fetch_recent_cves(
        hours=config.PERFORMANCE["cve_fetch_hours"],
        db=db
    )

    if not target_cves:
        logger.info("ì²˜ë¦¬í•  CVE ì—†ìŒ")
        return

    # Step 5: ìš°ì„ ìˆœìœ„ ì •ë ¬ + ë°°ì¹˜ ì œí•œ
    # ì‹ ê·œ CVE(is_new=True)ë¥¼ ë¨¼ì € ì²˜ë¦¬
    target_cves.sort(key=lambda x: (not x['is_new'],))

    max_per_run = config.PERFORMANCE.get("max_cves_per_run", 50)
    if len(target_cves) > max_per_run:
        logger.warning(f"CVE {len(target_cves)}ê±´ ì¤‘ ìƒìœ„ {max_per_run}ê±´ë§Œ ì²˜ë¦¬ (í• ë‹¹ëŸ‰ ë³´í˜¸)")
        target_cves = target_cves[:max_per_run]

    target_cve_ids = [c['cve_id'] for c in target_cves]

    # Step 6: EPSS ìˆ˜ì§‘
    collector.fetch_epss(target_cve_ids)

    logger.info(f"ë¶„ì„ ëŒ€ìƒ: {len(target_cve_ids)}ê±´")

    # Step 7: ë³‘ë ¬ ì²˜ë¦¬ë¡œ CVE ë¶„ì„
    results = []
    max_workers = config.PERFORMANCE["max_workers"]

    logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì›Œì»¤: {max_workers}ëª…)")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_cve = {
            executor.submit(process_single_cve, cve_id, collector, db, notifier): cve_id
            for cve_id in target_cve_ids
        }

        for future in as_completed(future_to_cve):
            cve_id = future_to_cve[future]
            try:
                result = future.result()
                if result:
                    results.append(result)
            except Exception as e:
                logger.error(f"{cve_id} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    # Step 8: Slack ë°°ì¹˜ ìš”ì•½ ì „ì†¡
    repo = os.environ.get("GITHUB_REPOSITORY", "")
    dashboard_url = f"https://{repo.split('/')[0].lower()}.github.io/{repo.split('/')[1]}/" if '/' in repo else None
    notifier.send_batch_summary(dashboard_url=dashboard_url)

    # Step 9: ê²°ê³¼ ìš”ì•½
    elapsed = time.time() - start_time
    logger.info("=" * 60)
    logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {len(results)}/{len(target_cve_ids)}ê±´ ì„±ê³µ")
    logger.info(f"ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    logger.info("=" * 60)

    # Step 10: Rate Limit ì‚¬ìš© ìš”ì•½
    rate_limit_manager.print_summary()

if __name__ == "__main__":
    main()