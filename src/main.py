import os
import datetime
import time
import requests
import pytz
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple, Optional
from google import genai
from google.genai import types

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“ˆë“¤
from logger import logger
from config import config
from collector import Collector
from database import ArgusDB
from notifier import SlackNotifier
from analyzer import Analyzer
from rule_manager import RuleManager
from rate_limiter import rate_limit_manager

# KST íƒ€ì„ì¡´ (í•œêµ­ í‘œì¤€ì‹œ)
KST = pytz.timezone('Asia/Seoul')

# Gemini í´ë¼ì´ì–¸íŠ¸ (í•œêµ­ì–´ ë²ˆì—­ìš©)
gemini_client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

# ==============================================================================
# [1] CVSS ë²¡í„° í•´ì„ ë§¤í•‘
# ==============================================================================
CVSS_MAP = {
    "AV:N": "ê³µê²© ê²½ë¡œ: ë„¤íŠ¸ì›Œí¬", "AV:A": "ê³µê²© ê²½ë¡œ: ì¸ì ‘", "AV:L": "ê³µê²© ê²½ë¡œ: ë¡œì»¬", "AV:P": "ê³µê²© ê²½ë¡œ: ë¬¼ë¦¬ì ",
    "AC:L": "ë³µì¡ì„±: ë‚®ìŒ", "AC:H": "ë³µì¡ì„±: ë†’ìŒ",
    "PR:N": "í•„ìš” ê¶Œí•œ: ì—†ìŒ", "PR:L": "í•„ìš” ê¶Œí•œ: ë‚®ìŒ", "PR:H": "í•„ìš” ê¶Œí•œ: ë†’ìŒ",
    "UI:N": "ì‚¬ìš©ì ê´€ì—¬: ì—†ìŒ", "UI:R": "ì‚¬ìš©ì ê´€ì—¬: í•„ìˆ˜",
    "S:U": "ë²”ìœ„: ë³€ê²½ ì—†ìŒ", "S:C": "ë²”ìœ„: ë³€ê²½ë¨",
    "C:H": "ê¸°ë°€ì„±: ë†’ìŒ", "C:L": "ê¸°ë°€ì„±: ë‚®ìŒ", "C:N": "ê¸°ë°€ì„±: ì—†ìŒ",
    "I:H": "ë¬´ê²°ì„±: ë†’ìŒ", "I:L": "ë¬´ê²°ì„±: ë‚®ìŒ", "I:N": "ë¬´ê²°ì„±: ì—†ìŒ",
    "A:H": "ê°€ìš©ì„±: ë†’ìŒ", "A:L": "ê°€ìš©ì„±: ë‚®ìŒ", "A:N": "ê°€ìš©ì„±: ì—†ìŒ",
}

# ==============================================================================
# [2] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ==============================================================================

def parse_cvss_vector(vector_str: str) -> str:
    """CVSS ë²¡í„° ë¬¸ìì—´ì„ í•œêµ­ì–´ë¡œ ë³€í™˜"""
    if not vector_str or vector_str == "N/A":
        return "ì •ë³´ ì—†ìŒ"
    
    parts = vector_str.split('/')
    mapped_parts = []
    
    for part in parts:
        if ':' in part:
            full_key = part
            desc = CVSS_MAP.get(full_key, f"**{part}**")
            if full_key in CVSS_MAP:
                mapped_parts.append(f"â€¢ {desc}")
            else:
                mapped_parts.append(f"â€¢ {part}")
    
    return "<br>".join(mapped_parts)

def is_target_asset(cve_description: str, cve_id: str) -> Tuple[bool, Optional[str]]:
    """ìì‚° í•„í„°ë§ (ê°ì‹œ ëŒ€ìƒì¸ì§€ í™•ì¸)"""
    desc_lower = cve_description.lower()
    
    for target in config.get_target_assets():
        vendor = target.get('vendor', '').lower()
        product = target.get('product', '').lower()
        
        if vendor == "*" and product == "*":
            return True, "All Assets (*)"
        
        if vendor in desc_lower and (product == "*" or product in desc_lower):
            return True, f"Matched: {vendor}/{product}"
    
    return False, None

def generate_korean_summary(cve_data: Dict) -> Tuple[str, str]:
    """Geminië¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ ë²ˆì—­"""
    prompt = f"""
Task: Translate Title and Summarize Description into Korean.
[Input] Title: {cve_data['title']} / Desc: {cve_data['description']}
[Format]
ì œëª©: [Korean Title]
ë‚´ìš©: [Korean Summary (Max 3 lines)]
Do NOT add intro/outro.
"""
    
    try:
        rate_limit_manager.check_and_wait("gemini")
        
        response = gemini_client.models.generate_content(
            model=config.MODEL_PHASE_0,
            contents=prompt,
            config=types.GenerateContentConfig(
                safety_settings=[types.SafetySetting(
                    category="HARM_CATEGORY_DANGEROUS_CONTENT",
                    threshold="BLOCK_NONE"
                )]
            )
        )
        
        rate_limit_manager.record_call("gemini")
        
        text = response.text.strip()
        title_ko, desc_ko = cve_data['title'], cve_data['description'][:200]
        
        for line in text.split('\n'):
            if line.startswith("ì œëª©:"):
                title_ko = line.replace("ì œëª©:", "").strip()
            if line.startswith("ë‚´ìš©:"):
                desc_ko = line.replace("ë‚´ìš©:", "").strip()
        
        return title_ko, desc_ko
        
    except Exception as e:
        logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨: {e}, ì›ë³¸ ì‚¬ìš©")
        return cve_data['title'], cve_data['description'][:200]

# ==============================================================================
# [3] GitHub Issue ìƒì„±/ì—…ë°ì´íŠ¸
# ==============================================================================

def create_github_issue(cve_data: Dict, reason: str) -> Tuple[Optional[str], Optional[Dict]]:
    """
    GitHub Issue ìƒì„±
    
    High Risk CVEì— ëŒ€í•´ ìƒì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ GitHub Issueë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    token = os.environ.get("GH_TOKEN")
    repo = os.environ.get("GITHUB_REPOSITORY")
    
    if not repo:
        logger.warning("GITHUB_REPOSITORY ë¯¸ì„¤ì •, Issue ìƒì„± ê±´ë„ˆëœ€")
        return None, None
    
    try:
        # Step 1: AI ë¶„ì„
        logger.info(f"AI ë¶„ì„ ì‹œì‘: {cve_data['id']}")
        analyzer = Analyzer()
        analysis = analyzer.analyze_cve(cve_data)
        
        # Step 2: ë£° ìƒì„±/ìˆ˜ì§‘
        logger.info(f"ë£° ìˆ˜ì§‘ ì‹œì‘: {cve_data['id']}")
        rule_manager = RuleManager()
        rules = rule_manager.get_rules(cve_data, analysis.get('rule_feasibility', False), analysis)
        
        # Step 3: ê³µì‹ ë£° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        has_official = any([
            rules.get('sigma') and rules['sigma'].get('verified'),
            any(r.get('verified') for r in rules.get('network', [])),
            rules.get('yara') and rules['yara'].get('verified')
        ])
        
        # Step 4: ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ êµ¬ì„±
        body = _build_issue_body(cve_data, reason, analysis, rules, has_official)
        
        # Step 5: GitHub API í˜¸ì¶œ
        rate_limit_manager.check_and_wait("github")
        
        url = f"https://api.github.com/repos/{repo}/issues"
        headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json"
        }
        payload = {
            "title": f"[Argus] {cve_data['id']}: {cve_data['title_ko']}",
            "body": body,
            "labels": ["security", "cve"]
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=15)
        response.raise_for_status()
        rate_limit_manager.record_call("github")
        
        issue_url = response.json().get("html_url")
        logger.info(f"GitHub Issue ìƒì„± ì„±ê³µ: {issue_url}")
        
        return issue_url, {"has_official": has_official, "rules": rules}
        
    except Exception as e:
        logger.error(f"GitHub Issue ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None

def _build_issue_body(cve_data: Dict, reason: str, analysis: Dict, rules: Dict, has_official: bool) -> str:
    """GitHub Issue ë³¸ë¬¸ êµ¬ì„±"""
    score = cve_data['cvss']
    if score >= 9.0: color = "FF0000"
    elif score >= 7.0: color = "FD7E14"
    elif score >= 4.0: color = "FFC107"
    elif score > 0: color = "28A745"
    else: color = "CCCCCC"
    
    kev_color = "FF0000" if cve_data['is_kev'] else "CCCCCC"
    
    badges = f"![CVSS](https://img.shields.io/badge/CVSS-{score}-{color}) ![EPSS](https://img.shields.io/badge/EPSS-{cve_data['epss']*100:.2f}%25-blue) ![KEV](https://img.shields.io/badge/KEV-{'YES' if cve_data['is_kev'] else 'No'}-{kev_color})"
    
    cwe_str = ", ".join(cve_data['cwe']) if cve_data['cwe'] else "N/A"
    
    # ì˜í–¥ë°›ëŠ” ìì‚° í…Œì´ë¸”
    affected_rows = ""
    for item in cve_data.get('affected', []):
        affected_rows += f"| {item['vendor']} | {item['product']} | {item['versions']} |\n"
    if not affected_rows:
        affected_rows = "| - | - | - |"
    
    # ëŒ€ì‘ ë°©ì•ˆ
    mitigation_list = "\n".join([f"- {m}" for m in analysis.get('mitigation', [])])
    
    # ì°¸ê³  ìë£Œ
    ref_list = "\n".join([f"- {r}" for r in cve_data['references']])
    
    # CVSS ë²¡í„° í•´ì„
    vector_details = parse_cvss_vector(cve_data.get('cvss_vector', 'N/A'))
    
    # ë£° ì„¹ì…˜
    rules_section = ""
    has_any_rules = rules.get('sigma') or rules.get('network') or rules.get('yara')
    
    if has_any_rules:
        rules_section = "## ğŸ›¡ï¸ íƒì§€ ë£° (Detection Rules)\n\n"
        
        if not has_official:
            rules_section += "> âš ï¸ **ì£¼ì˜:** AI ìƒì„± ë£°ì€ ì‹¤ì œ ë°°í¬ ì „ ë³´ì•ˆ ì „ë¬¸ê°€ì˜ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n\n"
        
        # Sigma ë£°
        if rules.get('sigma'):
            is_verified = rules['sigma'].get('verified')
            badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
            
            indicator_info = ""
            if not is_verified and rules['sigma'].get('indicators'):
                indicators = rules['sigma']['indicators']
                if indicators:
                    indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
            
            rules_section += f"### Sigma Rule ({rules['sigma']['source']}) {badge}\n{indicator_info}```yaml\n{rules['sigma']['code']}\n```\n\n"
        
        # ë„¤íŠ¸ì›Œí¬ ë£° (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)
        if rules.get('network'):
            for idx, net_rule in enumerate(rules['network'], 1):
                is_verified = net_rule.get('verified')
                badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
                engine_name = net_rule.get('engine', 'unknown').upper()
                
                indicator_info = ""
                if not is_verified and net_rule.get('indicators'):
                    indicators = net_rule['indicators']
                    if indicators:
                        indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
                
                rules_section += f"### Network Rule #{idx} ({net_rule['source']} - {engine_name}) {badge}\n{indicator_info}```bash\n{net_rule['code']}\n```\n\n"
        
        # Yara ë£°
        if rules.get('yara'):
            is_verified = rules['yara'].get('verified')
            badge = "ğŸŸ¢ **ê³µì‹ ê²€ì¦**" if is_verified else "ğŸ”¶ **AI ìƒì„± - ê²€í†  í•„ìš”**"
            
            indicator_info = ""
            if not is_verified and rules['yara'].get('indicators'):
                indicators = rules['yara']['indicators']
                if indicators:
                    indicator_info = f"\n> **Based on:** {', '.join(indicators)}\n"
            
            rules_section += f"### Yara Rule ({rules['yara']['source']}) {badge}\n{indicator_info}```yara\n{rules['yara']['code']}\n```\n\n"
    
    now_kst = datetime.datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S (KST)')
    
    body = f"""# ğŸ›¡ï¸ {cve_data['title_ko']}

> **íƒì§€ ì¼ì‹œ:** {now_kst}
> **íƒì§€ ì‚¬ìœ :** {reason}

{badges}
**ì·¨ì•½ì  ìœ í˜• (CWE):** {cwe_str}

## ğŸ“¦ ì˜í–¥ ë°›ëŠ” ìì‚°
| ë²¤ë” | ì œí’ˆ | ë²„ì „ |
| :--- | :--- | :--- |
{affected_rows}

## ğŸ” ì‹¬ì¸µ ë¶„ì„
| í•­ëª© | ë‚´ìš© |
| :--- | :--- |
| **ê¸°ìˆ ì  ì›ì¸** | {analysis.get('root_cause', '-')} |
| **ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥** | {analysis.get('impact', '-')} |

### ğŸ¹ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤
> {analysis.get('scenario', 'ì •ë³´ ì—†ìŒ')}

### ğŸ¹ ê³µê²© ë²¡í„° ìƒì„¸
| í•­ëª© | ë‚´ìš© |
| :--- | :--- |
| **ê³µì‹ ë²¡í„°** | `{cve_data.get('cvss_vector', 'N/A')}` |
| **ìƒì„¸ ë¶„ì„** | {vector_details} |

## ğŸ›¡ï¸ ëŒ€ì‘ ë°©ì•ˆ
{mitigation_list}

{rules_section}

## ğŸ”— ì°¸ê³  ìë£Œ
{ref_list}
"""
    return body.strip()

def update_github_issue_with_official_rules(issue_url: str, cve_id: str, rules: Dict) -> bool:
    """GitHub Issueì— ê³µì‹ ë£° ë°œê²¬ ëŒ“ê¸€ ì¶”ê°€"""
    comment = f"""## âœ… ê³µì‹ íƒì§€ ë£° ë°œê²¬

{cve_id}ì— ëŒ€í•œ **ê³µì‹ ê²€ì¦ëœ íƒì§€ ë£°**ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. AI ìƒì„± ë£°ì„ ì´ê²ƒìœ¼ë¡œ êµì²´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

"""
    
    if rules.get('sigma') and rules['sigma'].get('verified'):
        comment += f"### Sigma Rule ({rules['sigma']['source']})\n```yaml\n{rules['sigma']['code']}\n```\n\n"
    
    if rules.get('network'):
        for idx, net_rule in enumerate(rules['network'], 1):
            if net_rule.get('verified'):
                engine = net_rule.get('engine', 'unknown').upper()
                comment += f"### Network Rule #{idx} ({net_rule['source']} - {engine})\n```bash\n{net_rule['code']}\n```\n\n"
    
    if rules.get('yara') and rules['yara'].get('verified'):
        comment += f"### Yara Rule ({rules['yara']['source']})\n```yara\n{rules['yara']['code']}\n```\n\n"
    
    notifier = SlackNotifier()
    return notifier.update_github_issue(issue_url, comment)

# ==============================================================================
# [4] CVE ì²˜ë¦¬ (ë‹¨ì¼)
# ==============================================================================

def process_single_cve(cve_id: str, collector: Collector, db: ArgusDB, notifier: SlackNotifier) -> Optional[Dict]:
    """
    ë‹¨ì¼ CVE ì²˜ë¦¬
    
    ê³¼ì •:
    1. CVE ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    2. ìì‚° í•„í„°ë§
    3. ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨
    4. High Riskë©´ GitHub Issue ìƒì„±
    5. Slack ì•Œë¦¼ ì „ì†¡
    6. DBì— ì €ì¥
    """
    try:
        # Step 1: CVE ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        raw_data = collector.enrich_cve(cve_id)
        
        if raw_data.get('state') != 'PUBLISHED':
            logger.debug(f"{cve_id}: PUBLISHED ìƒíƒœ ì•„ë‹˜, ê±´ë„ˆëœ€")
            return None
        
        # Step 2: ìì‚° í•„í„°ë§
        is_target, match_info = is_target_asset(raw_data['description'], cve_id)
        if not is_target:
            logger.debug(f"{cve_id}: ê°ì‹œ ëŒ€ìƒ ì•„ë‹˜, ê±´ë„ˆëœ€")
            return None
        
        # Step 3: í˜„ì¬ ìƒíƒœ êµ¬ì„±
        current_state = {
            "id": cve_id,
            "title": raw_data['title'],
            "cvss": raw_data['cvss'],
            "cvss_vector": raw_data['cvss_vector'],
            "is_kev": cve_id in collector.kev_set,
            "epss": collector.epss_cache.get(cve_id, 0.0),
            "description": raw_data['description'],
            "cwe": raw_data['cwe'],
            "references": raw_data['references'],
            "affected": raw_data['affected']
        }
        
        # Step 4: ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨
        last_record = db.get_cve(cve_id)
        last_state = last_record.get('last_alert_state') if last_record else None
        
        should_alert, alert_reason, is_high_risk = _should_send_alert(
            current_state, last_state
        )
        
        if not should_alert:
            db.upsert_cve({
                "id": cve_id,
                "updated_at": datetime.datetime.now(KST).isoformat()
            })
            return None
        
        # Step 5: í•œêµ­ì–´ ë²ˆì—­
        logger.info(f"ì•Œë¦¼ ë°œì†¡ ì¤€ë¹„: {cve_id} (HighRisk: {is_high_risk})")
        title_ko, desc_ko = generate_korean_summary(current_state)
        current_state['title_ko'] = title_ko
        current_state['desc_ko'] = desc_ko
        
        # Step 6: High Riskë©´ GitHub Issue ìƒì„±
        report_url = None
        rules_info = None
        if is_high_risk:
            report_url, rules_info = create_github_issue(current_state, alert_reason)
        
        # Step 7: Slack ì•Œë¦¼
        notifier.send_alert(current_state, alert_reason, report_url)
        
        # Step 8: DB ì €ì¥
        db_data = {
            "id": cve_id,
            "cvss_score": current_state['cvss'],
            "epss_score": current_state['epss'],
            "is_kev": current_state['is_kev'],
            "last_alert_at": datetime.datetime.now(KST).isoformat(),
            "last_alert_state": current_state,
            "report_url": report_url,
            "updated_at": datetime.datetime.now(KST).isoformat()
        }
        
        if rules_info:
            db_data["has_official_rules"] = rules_info.get('has_official', False)
            db_data["rules_snapshot"] = rules_info.get('rules')
            db_data["last_rule_check_at"] = datetime.datetime.now(KST).isoformat()
        
        db.upsert_cve(db_data)
        
        return {"cve_id": cve_id, "status": "success"}
        
    except Exception as e:
        logger.error(f"{cve_id} ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        return None

def _should_send_alert(current: Dict, last: Optional[Dict]) -> Tuple[bool, str, bool]:
    """ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨"""
    is_high_risk = current['cvss'] >= 7.0 or current['is_kev']
    
    if last is None:
        return True, "ì‹ ê·œ ì·¨ì•½ì ", is_high_risk
    
    if current['is_kev'] and not last.get('is_kev'):
        return True, "ğŸš¨ KEV ë“±ì¬", True
    
    if current['epss'] >= 0.1 and (current['epss'] - last.get('epss', 0)) > 0.05:
        return True, "ğŸ“ˆ EPSS ê¸‰ì¦", True
    
    if current['cvss'] >= 7.0 and last.get('cvss', 0) < 7.0:
        return True, "ğŸ”º CVSS ìœ„í—˜ë„ ìƒí–¥", True
    
    return False, "", is_high_risk

# ==============================================================================
# [5] ê³µì‹ ë£° ì¬ë°œê²¬
# ==============================================================================

def check_for_official_rules() -> None:
    """
    AI ìƒì„± ë£° CVEì˜ ê³µì‹ ë£° ì¬ë°œê²¬
    
    v2.0 ë³€ê²½ì‚¬í•­:
    - RuleManager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê³µìœ í•˜ì—¬ ë£°ì…‹ ìºì‹œ ì¬í™œìš©
    - rate_limit_managerê°€ GitHub Search ê°„ê²©ì„ ìë™ ê´€ë¦¬
    - ê°œë³„ CVE ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
    """
    try:
        logger.info("=== ê³µì‹ ë£° ì¬ë°œê²¬ ì²´í¬ ì‹œì‘ ===")
        
        db = ArgusDB()
        notifier = SlackNotifier()
        collector = Collector()
        
        # âœ… RuleManagerë¥¼ í•œ ë²ˆë§Œ ìƒì„±í•˜ì—¬ ë£°ì…‹ ìºì‹œ ê³µìœ 
        rule_manager = RuleManager()
        
        ai_cves = db.get_ai_generated_cves()
        
        if not ai_cves:
            logger.info("ì¬í™•ì¸ ëŒ€ìƒ ì—†ìŒ")
            return
        
        logger.info(f"ì¬í™•ì¸ ëŒ€ìƒ: {len(ai_cves)}ê±´")
        
        # âœ… GitHub Search API í˜„ì¬ ìƒíƒœ ë¡œê¹…
        search_status = rate_limit_manager.get_status("github_search")
        logger.info(
            f"GitHub Search API ìƒíƒœ: "
            f"{search_status.get('used', 0)}/{search_status.get('limit', 0)} "
            f"(ì”ì—¬: {search_status.get('remaining', 0)})"
        )
        
        for idx, record in enumerate(ai_cves, 1):
            cve_id = record['id']
            
            try:
                logger.info(f"[{idx}/{len(ai_cves)}] {cve_id} ê³µì‹ ë£° ì¬í™•ì¸ ì¤‘...")
                
                # CVE ì •ë³´ ì¬ìˆ˜ì§‘
                raw_data = collector.enrich_cve(cve_id)
                if raw_data.get('state') != 'PUBLISHED':
                    logger.debug(f"{cve_id}: PUBLISHED ìƒíƒœ ì•„ë‹˜, ê±´ë„ˆëœ€")
                    continue
                
                cve_temp = {
                    "id": cve_id,
                    "description": raw_data['description'],
                    "cvss_vector": raw_data['cvss_vector'],
                    "cwe": raw_data['cwe'],
                    "references": raw_data.get('references', []),
                    "affected": raw_data.get('affected', [])
                }
                
                # âœ… ê³µê°œ ë£°ë§Œ ê²€ìƒ‰ (analysis=Noneì´ë©´ AI ìƒì„± ì‹œë„ ì•ˆ í•¨? ì•„ë‹˜!)
                #    get_rulesëŠ” ê³µê°œ ë£° ì—†ìœ¼ë©´ AI ìƒì„±ì„ ì‹œë„í•˜ì§€ë§Œ,
                #    ì¬ë°œê²¬ ëª©ì ì´ë¯€ë¡œ ê³µì‹ ë£°ë§Œ ì²´í¬í•˜ë©´ ë¨.
                #    í•˜ì§€ë§Œ í˜„ì¬ êµ¬ì¡°ìƒ get_rulesë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
                rules = rule_manager.get_rules(cve_temp, feasibility=True, analysis=None)
                
                # ê³µì‹ ë£° ì¡´ì¬ í™•ì¸
                has_official = any([
                    rules.get('sigma') and rules['sigma'].get('verified'),
                    any(r.get('verified') for r in rules.get('network', [])),
                    rules.get('yara') and rules['yara'].get('verified')
                ])
                
                if has_official:
                    logger.info(f"âœ… {cve_id}: ê³µì‹ ë£° ë°œê²¬!")
                    
                    title_ko = record.get('last_alert_state', {}).get('title_ko', cve_id)
                    notifier.send_official_rule_update(
                        cve_id=cve_id,
                        title=title_ko,
                        rules_info=rules,
                        original_report_url=record.get('report_url')
                    )
                    
                    if record.get('report_url'):
                        update_github_issue_with_official_rules(
                            record['report_url'],
                            cve_id,
                            rules
                        )
                    
                    db.upsert_cve({
                        "id": cve_id,
                        "has_official_rules": True,
                        "rules_snapshot": rules,
                        "last_rule_check_at": datetime.datetime.now(KST).isoformat(),
                        "updated_at": datetime.datetime.now(KST).isoformat()
                    })
                else:
                    logger.debug(f"{cve_id}: ê³µì‹ ë£° ì•„ì§ ì—†ìŒ")
                
            except Exception as e:
                logger.warning(f"{cve_id} ê³µì‹ ë£° ì²´í¬ ì‹¤íŒ¨: {e}")
                continue
        
        logger.info("=== ê³µì‹ ë£° ì¬ë°œê²¬ ì²´í¬ ì™„ë£Œ ===")
        
    except Exception as e:
        logger.error(f"ê³µì‹ ë£° ì²´í¬ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")

# ==============================================================================
# [6] ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ==============================================================================

def main():
    """
    Argus ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    v2.0 ë³€ê²½ì‚¬í•­:
    - rate_limit_manager.print_summary() ì¶”ê°€ (ì¢…ë£Œ ì‹œ API ì‚¬ìš©ëŸ‰ ì¶œë ¥)
    - ë¡œê·¸ í†µì¼ì„± ê°œì„ 
    """
    start_time = time.time()
    logger.info("=" * 60)
    logger.info(f"Argus Phase 1 ì‹œì‘ (Model: {config.MODEL_PHASE_1})")
    logger.info("=" * 60)
    
    # Step 1: í—¬ìŠ¤ì²´í¬
    health = config.health_check()
    if not all(health.values()):
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {health}")
        return
    logger.info(f"âœ… í—¬ìŠ¤ì²´í¬ í†µê³¼: {health}")
    
    # Step 2: ëª¨ë“ˆ ì´ˆê¸°í™”
    collector = Collector()
    db = ArgusDB()
    notifier = SlackNotifier()
    
    # Step 3: ê³µì‹ ë£° ì¬ë°œê²¬
    check_for_official_rules()
    
    # Step 4: KEV ë° ìµœì‹  CVE ìˆ˜ì§‘
    collector.fetch_kev()
    target_cve_ids = collector.fetch_recent_cves(hours=config.PERFORMANCE["cve_fetch_hours"])
    
    if not target_cve_ids:
        logger.info("ì²˜ë¦¬í•  CVE ì—†ìŒ")
        # âœ… CVE ì—†ì–´ë„ rate limit ìš”ì•½ì€ ì¶œë ¥
        _print_final_summary(start_time, 0, 0)
        return
    
    # Step 5: EPSS ìˆ˜ì§‘
    collector.fetch_epss(target_cve_ids)
    
    logger.info(f"ë¶„ì„ ëŒ€ìƒ: {len(target_cve_ids)}ê±´")
    
    # Step 6: ë³‘ë ¬ ì²˜ë¦¬ë¡œ CVE ë¶„ì„
    results = []
    max_workers = config.PERFORMANCE["max_workers"]
    
    logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì›Œì»¤: {max_workers}ëª…)")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_cve = {
            executor.submit(process_single_cve, cve_id, collector, db, notifier): cve_id
            for cve_id in target_cve_ids
        }
        
        for future in as_completed(future_to_cve):
            cve_id = future_to_cve[future]
            try:
                result = future.result()
                if result:
                    results.append(result)
            except Exception as e:
                logger.error(f"{cve_id} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    
    # Step 7: ê²°ê³¼ ìš”ì•½
    _print_final_summary(start_time, len(results), len(target_cve_ids))

def _print_final_summary(start_time: float, success_count: int, total_count: int):
    """
    ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    
    ì²˜ë¦¬ ê²°ê³¼ + Rate Limit ì‚¬ìš©ëŸ‰ì„ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    elapsed = time.time() - start_time
    
    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ“‹ Argus ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 60)
    logger.info(f"  ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{total_count}ê±´ ì„±ê³µ")
    logger.info(f"  ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    logger.info("=" * 60)
    
    # âœ… Rate Limit ì‚¬ìš© ìš”ì•½
    rate_limit_manager.print_summary()

if __name__ == "__main__":
    main()
